{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EmployeeCode</th>\n",
       "      <th>Technical Score_JD</th>\n",
       "      <th>Programming Score_JD</th>\n",
       "      <th>Soft Score_with_JD</th>\n",
       "      <th>Education_match_Score_with_JD</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Department</th>\n",
       "      <th>JobCategory</th>\n",
       "      <th>ProficiencyLevel</th>\n",
       "      <th>...</th>\n",
       "      <th>Total Experience in Years</th>\n",
       "      <th>Number of Goal Assigned</th>\n",
       "      <th>Number of Goals Achieved</th>\n",
       "      <th>Final Score</th>\n",
       "      <th>Goals Score</th>\n",
       "      <th>Competency Score</th>\n",
       "      <th>Cultural Value Score</th>\n",
       "      <th>Additional Accomplishment Score</th>\n",
       "      <th>Potential Assessment Score</th>\n",
       "      <th>Trait Assessment Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EMP9004</td>\n",
       "      <td>0.257062</td>\n",
       "      <td>0.667620</td>\n",
       "      <td>0.468664</td>\n",
       "      <td>0.573545</td>\n",
       "      <td>Male</td>\n",
       "      <td>41</td>\n",
       "      <td>Data and AI</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Senior</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>34.180251</td>\n",
       "      <td>76.488103</td>\n",
       "      <td>7.08</td>\n",
       "      <td>51.806653</td>\n",
       "      <td>55.141563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EMP9005</td>\n",
       "      <td>0.171806</td>\n",
       "      <td>0.543745</td>\n",
       "      <td>0.468005</td>\n",
       "      <td>0.648808</td>\n",
       "      <td>Female</td>\n",
       "      <td>33</td>\n",
       "      <td>Data and AI</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Mid-Level</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>30.775600</td>\n",
       "      <td>63.895969</td>\n",
       "      <td>1.63</td>\n",
       "      <td>40.425636</td>\n",
       "      <td>54.988743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EMP9009</td>\n",
       "      <td>0.237569</td>\n",
       "      <td>0.667620</td>\n",
       "      <td>0.509374</td>\n",
       "      <td>0.675198</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>Data and AI</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Mid-Level</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>42.857143</td>\n",
       "      <td>20.708582</td>\n",
       "      <td>57.979997</td>\n",
       "      <td>8.01</td>\n",
       "      <td>30.443135</td>\n",
       "      <td>36.977535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EMP9015</td>\n",
       "      <td>0.253079</td>\n",
       "      <td>0.646303</td>\n",
       "      <td>0.453373</td>\n",
       "      <td>0.634185</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>Data and AI</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Senior</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>18.998407</td>\n",
       "      <td>66.495545</td>\n",
       "      <td>5.71</td>\n",
       "      <td>43.893732</td>\n",
       "      <td>45.595596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EMP9021</td>\n",
       "      <td>0.163569</td>\n",
       "      <td>0.646303</td>\n",
       "      <td>0.418016</td>\n",
       "      <td>0.721195</td>\n",
       "      <td>Male</td>\n",
       "      <td>59</td>\n",
       "      <td>Data and AI</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Expert</td>\n",
       "      <td>...</td>\n",
       "      <td>37</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>56.717347</td>\n",
       "      <td>73.333333</td>\n",
       "      <td>32.126666</td>\n",
       "      <td>78.174790</td>\n",
       "      <td>2.63</td>\n",
       "      <td>61.771810</td>\n",
       "      <td>50.283365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  EmployeeCode  Technical Score_JD  Programming Score_JD  Soft Score_with_JD  \\\n",
       "0      EMP9004            0.257062              0.667620            0.468664   \n",
       "1      EMP9005            0.171806              0.543745            0.468005   \n",
       "2      EMP9009            0.237569              0.667620            0.509374   \n",
       "3      EMP9015            0.253079              0.646303            0.453373   \n",
       "4      EMP9021            0.163569              0.646303            0.418016   \n",
       "\n",
       "   Education_match_Score_with_JD  Gender  Age   Department     JobCategory  \\\n",
       "0                       0.573545    Male   41  Data and AI  Data Scientist   \n",
       "1                       0.648808  Female   33  Data and AI   Data Engineer   \n",
       "2                       0.675198    Male   35  Data and AI  Data Scientist   \n",
       "3                       0.634185    Male   42  Data and AI  Data Scientist   \n",
       "4                       0.721195    Male   59  Data and AI    Data Analyst   \n",
       "\n",
       "  ProficiencyLevel  ... Total Experience in Years  Number of Goal Assigned  \\\n",
       "0           Senior  ...                        19                       10   \n",
       "1        Mid-Level  ...                        11                       10   \n",
       "2        Mid-Level  ...                        13                        7   \n",
       "3           Senior  ...                        20                       10   \n",
       "4           Expert  ...                        37                       15   \n",
       "\n",
       "  Number of Goals Achieved Final Score Goals Score  Competency Score  \\\n",
       "0                        7   35.000000   70.000000         34.180251   \n",
       "1                        5   35.000000   50.000000         30.775600   \n",
       "2                        3   35.000000   42.857143         20.708582   \n",
       "3                        5   35.000000   50.000000         18.998407   \n",
       "4                       11   56.717347   73.333333         32.126666   \n",
       "\n",
       "   Cultural Value Score  Additional Accomplishment Score  \\\n",
       "0             76.488103                             7.08   \n",
       "1             63.895969                             1.63   \n",
       "2             57.979997                             8.01   \n",
       "3             66.495545                             5.71   \n",
       "4             78.174790                             2.63   \n",
       "\n",
       "   Potential Assessment Score  Trait Assessment Score  \n",
       "0                   51.806653               55.141563  \n",
       "1                   40.425636               54.988743  \n",
       "2                   30.443135               36.977535  \n",
       "3                   43.893732               45.595596  \n",
       "4                   61.771810               50.283365  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_excel('C://Users//DanukaDilshanRathnay//Desktop//AI-Driven-Job-Role-Fit-Prediction//code//Dataset//Similarity_with_EMP_data.xlsx')\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_ids = df1[\"EmployeeCode\"]\n",
    "\n",
    "df = df1.drop(columns=[\"EmployeeCode\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "un_col=['Gender','Department', 'JobCategory', 'ProficiencyLevel',\n",
    "       'Education Qualifications', 'Professional Qualifications','Final Score','Age','List of Software Skills','Number of Goal Assigned', 'Number of Goals Achieved','Projects Completed',\"Total Experience in Years\",\"Absentism Rate\"]\n",
    "df_n=df.drop(columns=un_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 240 entries, 0 to 239\n",
      "Data columns (total 14 columns):\n",
      " #   Column                                  Non-Null Count  Dtype  \n",
      "---  ------                                  --------------  -----  \n",
      " 0   Technical Score_JD                      240 non-null    float64\n",
      " 1   Programming Score_JD                    240 non-null    float64\n",
      " 2   Soft Score_with_JD                      240 non-null    float64\n",
      " 3   Education_match_Score_with_JD           240 non-null    float64\n",
      " 4   Years of Experience in this Company     240 non-null    int64  \n",
      " 5   KPI                                     240 non-null    float64\n",
      " 6   Employee Satisfaction Score             240 non-null    float64\n",
      " 7   Experience in Years Previous Positions  240 non-null    int64  \n",
      " 8   Goals Score                             240 non-null    float64\n",
      " 9   Competency Score                        240 non-null    float64\n",
      " 10  Cultural Value Score                    240 non-null    float64\n",
      " 11  Additional Accomplishment Score         240 non-null    float64\n",
      " 12  Potential Assessment Score              240 non-null    float64\n",
      " 13  Trait Assessment Score                  240 non-null    float64\n",
      "dtypes: float64(12), int64(2)\n",
      "memory usage: 26.4 KB\n"
     ]
    }
   ],
   "source": [
    "df_n.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Technical Score_JD</th>\n",
       "      <th>Programming Score_JD</th>\n",
       "      <th>Soft Score_with_JD</th>\n",
       "      <th>Education_match_Score_with_JD</th>\n",
       "      <th>Years of Experience in this Company</th>\n",
       "      <th>KPI</th>\n",
       "      <th>Employee Satisfaction Score</th>\n",
       "      <th>Experience in Years Previous Positions</th>\n",
       "      <th>Goals Score</th>\n",
       "      <th>Competency Score</th>\n",
       "      <th>Cultural Value Score</th>\n",
       "      <th>Additional Accomplishment Score</th>\n",
       "      <th>Potential Assessment Score</th>\n",
       "      <th>Trait Assessment Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.513790</td>\n",
       "      <td>0.646515</td>\n",
       "      <td>0.741535</td>\n",
       "      <td>-0.880730</td>\n",
       "      <td>-0.590303</td>\n",
       "      <td>-0.233031</td>\n",
       "      <td>0.276858</td>\n",
       "      <td>0.597193</td>\n",
       "      <td>0.639453</td>\n",
       "      <td>0.728677</td>\n",
       "      <td>0.884639</td>\n",
       "      <td>0.656303</td>\n",
       "      <td>0.436509</td>\n",
       "      <td>0.462198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.919798</td>\n",
       "      <td>-0.451721</td>\n",
       "      <td>0.733751</td>\n",
       "      <td>0.312989</td>\n",
       "      <td>-0.455248</td>\n",
       "      <td>-0.471827</td>\n",
       "      <td>-1.028983</td>\n",
       "      <td>-0.516742</td>\n",
       "      <td>-0.396366</td>\n",
       "      <td>0.357783</td>\n",
       "      <td>-0.461913</td>\n",
       "      <td>-1.204903</td>\n",
       "      <td>-0.334448</td>\n",
       "      <td>0.444873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.186014</td>\n",
       "      <td>0.646515</td>\n",
       "      <td>1.222497</td>\n",
       "      <td>0.731556</td>\n",
       "      <td>-0.995468</td>\n",
       "      <td>-1.425184</td>\n",
       "      <td>0.269708</td>\n",
       "      <td>0.225881</td>\n",
       "      <td>-0.766302</td>\n",
       "      <td>-0.738894</td>\n",
       "      <td>-1.094544</td>\n",
       "      <td>0.973903</td>\n",
       "      <td>-1.010668</td>\n",
       "      <td>-1.597004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.446811</td>\n",
       "      <td>0.457528</td>\n",
       "      <td>0.560877</td>\n",
       "      <td>0.081058</td>\n",
       "      <td>-0.995468</td>\n",
       "      <td>-1.265382</td>\n",
       "      <td>-0.666101</td>\n",
       "      <td>1.092276</td>\n",
       "      <td>-0.396366</td>\n",
       "      <td>-0.925196</td>\n",
       "      <td>-0.183925</td>\n",
       "      <td>0.188440</td>\n",
       "      <td>-0.099517</td>\n",
       "      <td>-0.620000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.058308</td>\n",
       "      <td>0.457528</td>\n",
       "      <td>0.143155</td>\n",
       "      <td>1.461114</td>\n",
       "      <td>0.625192</td>\n",
       "      <td>1.658107</td>\n",
       "      <td>1.505833</td>\n",
       "      <td>1.711129</td>\n",
       "      <td>0.812089</td>\n",
       "      <td>0.504965</td>\n",
       "      <td>1.065007</td>\n",
       "      <td>-0.863398</td>\n",
       "      <td>1.111555</td>\n",
       "      <td>-0.088562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Technical Score_JD  Programming Score_JD  Soft Score_with_JD  \\\n",
       "0            0.513790              0.646515            0.741535   \n",
       "1           -0.919798             -0.451721            0.733751   \n",
       "2            0.186014              0.646515            1.222497   \n",
       "3            0.446811              0.457528            0.560877   \n",
       "4           -1.058308              0.457528            0.143155   \n",
       "\n",
       "   Education_match_Score_with_JD  Years of Experience in this Company  \\\n",
       "0                      -0.880730                            -0.590303   \n",
       "1                       0.312989                            -0.455248   \n",
       "2                       0.731556                            -0.995468   \n",
       "3                       0.081058                            -0.995468   \n",
       "4                       1.461114                             0.625192   \n",
       "\n",
       "        KPI  Employee Satisfaction Score  \\\n",
       "0 -0.233031                     0.276858   \n",
       "1 -0.471827                    -1.028983   \n",
       "2 -1.425184                     0.269708   \n",
       "3 -1.265382                    -0.666101   \n",
       "4  1.658107                     1.505833   \n",
       "\n",
       "   Experience in Years Previous Positions  Goals Score  Competency Score  \\\n",
       "0                                0.597193     0.639453          0.728677   \n",
       "1                               -0.516742    -0.396366          0.357783   \n",
       "2                                0.225881    -0.766302         -0.738894   \n",
       "3                                1.092276    -0.396366         -0.925196   \n",
       "4                                1.711129     0.812089          0.504965   \n",
       "\n",
       "   Cultural Value Score  Additional Accomplishment Score  \\\n",
       "0              0.884639                         0.656303   \n",
       "1             -0.461913                        -1.204903   \n",
       "2             -1.094544                         0.973903   \n",
       "3             -0.183925                         0.188440   \n",
       "4              1.065007                        -0.863398   \n",
       "\n",
       "   Potential Assessment Score  Trait Assessment Score  \n",
       "0                    0.436509                0.462198  \n",
       "1                   -0.334448                0.444873  \n",
       "2                   -1.010668               -1.597004  \n",
       "3                   -0.099517               -0.620000  \n",
       "4                    1.111555               -0.088562  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "sd=StandardScaler()\n",
    "mn=MinMaxScaler()\n",
    "df_con=sd.fit_transform(df_n)\n",
    "df_con=pd.DataFrame(df_con,columns=df_n.columns)\n",
    "df_con.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use PCA to create new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca=PCA(n_components=0.95)\n",
    "df_pca=pca.fit_transform(df_con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.65911996 2.43917849 1.4046136  1.17700872 1.01807232 1.00041382\n",
      " 0.94461265 0.71108706 0.65672666 0.33351478 0.29758271]\n"
     ]
    }
   ],
   "source": [
    "eigenvalues=pca.explained_variance_\n",
    "print(eigenvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 11)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pca.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### apply this careted data set into Auto encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import keras_tuner as kt\n",
    "import random\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pca=mn.fit_transform(df_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(df_pca, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 00m 05s]\n",
      "val_loss: 0.038245245814323425\n",
      "\n",
      "Best val_loss So Far: 0.030869193375110626\n",
      "Total elapsed time: 00h 00m 22s\n"
     ]
    }
   ],
   "source": [
    "from keras.regularizers import l2, l1\n",
    "import keras_tuner as kt\n",
    "\n",
    "def build_autoencoder(hp):\n",
    "    input_dim = X_train.shape[1]\n",
    "    encoding_dim = hp.Int(\"encoding_dim\", min_value=2, max_value=max(4, input_dim // 2), step=1)  # Reduced max_value\n",
    "\n",
    "    # Regularization strength hyperparameters (more conservative range)\n",
    "    l2_reg = hp.Float(\"l2_reg\", min_value=1e-6, max_value=1e-4, sampling=\"log\")\n",
    "    dropout_rate = hp.Float(\"dropout_rate\", min_value=0.05, max_value=0.2, step=0.05)\n",
    "    l1_reg = hp.Float(\"l1_reg\", min_value=1e-6, max_value=1e-4, sampling=\"log\")  # Sparsity regularization\n",
    "\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "\n",
    "    # First hidden layer with L2 regularization and dropout\n",
    "    # Fewer units in the first layer\n",
    "    encoded = Dense(hp.Int(\"units1\", min_value=4, max_value=32, step=4),\n",
    "                    activation=hp.Choice(\"activation1\", [\"relu\", \"tanh\"]),\n",
    "                    kernel_regularizer=l2(l2_reg))(input_layer)\n",
    "    encoded = Dropout(dropout_rate)(encoded)\n",
    "\n",
    "    # Latent space with L1 sparsity constraint\n",
    "    encoded = Dense(encoding_dim, activation=\"relu\", activity_regularizer=l1(l1_reg))(encoded)\n",
    "\n",
    "    # Decoder with L2 regularization and dropout\n",
    "    # Simpler decoder\n",
    "    decoded = Dense(hp.Int(\"units2\", min_value=4, max_value=32, step=4),\n",
    "                    activation=hp.Choice(\"activation2\", [\"relu\", \"tanh\"]),\n",
    "                    kernel_regularizer=l2(l2_reg))(encoded)\n",
    "    decoded = Dropout(dropout_rate)(decoded)\n",
    "    decoded = Dense(input_dim, activation=\"sigmoid\")(decoded)\n",
    "\n",
    "    autoencoder = Model(input_layer, decoded)\n",
    "    autoencoder.compile(optimizer=Adam(learning_rate=hp.Choice(\"learning_rate\", [0.001, 0.0005, 0.0001])),\n",
    "                        loss=\"mse\")\n",
    "\n",
    "    return autoencoder\n",
    "\n",
    "# Hyperparameter tuning with Keras Tuner\n",
    "tuner = kt.RandomSearch(\n",
    "    build_autoencoder,\n",
    "    objective=\"val_loss\",\n",
    "    max_trials=5,  # Fewer trials to prevent excessive fitting to the small dataset\n",
    "    executions_per_trial=1,  # Reduce the number of executions to minimize variance effects\n",
    "    directory=\"autoencoder_tuning_hy\",\n",
    "    project_name=\"employee_autoencoder_hy\"\n",
    ")\n",
    "\n",
    "# Search for the best hyperparameters\n",
    "tuner.search(X_train, X_train, epochs=20, batch_size=8, validation_data=(X_test, X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Encoding Dim: 3\n",
      "Best Layer 1 Units: 8, Activation: relu\n",
      "Best Layer 2 Units: 28, Activation: tanh\n",
      "Best Learning Rate: 0.001\n",
      "Epoch 1/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0381 - val_loss: 0.0411\n",
      "Epoch 2/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0370 - val_loss: 0.0402\n",
      "Epoch 3/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0364 - val_loss: 0.0394\n",
      "Epoch 4/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0355 - val_loss: 0.0385\n",
      "Epoch 5/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0348 - val_loss: 0.0378\n",
      "Epoch 6/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0341 - val_loss: 0.0371\n",
      "Epoch 7/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0335 - val_loss: 0.0365\n",
      "Epoch 8/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0330 - val_loss: 0.0361\n",
      "Epoch 9/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0327 - val_loss: 0.0358\n",
      "Epoch 10/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0324 - val_loss: 0.0356\n",
      "Epoch 11/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0323 - val_loss: 0.0354\n",
      "Epoch 12/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0321 - val_loss: 0.0353\n",
      "Epoch 13/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0322 - val_loss: 0.0353\n",
      "Epoch 14/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0320 - val_loss: 0.0352\n",
      "Epoch 15/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0320 - val_loss: 0.0352\n",
      "Epoch 16/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0319 - val_loss: 0.0350\n",
      "Epoch 17/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0316 - val_loss: 0.0345\n",
      "Epoch 18/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0312 - val_loss: 0.0343\n",
      "Epoch 19/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0305 - val_loss: 0.0340\n",
      "Epoch 20/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0302 - val_loss: 0.0338\n",
      "Epoch 21/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0299 - val_loss: 0.0336\n",
      "Epoch 22/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0298 - val_loss: 0.0334\n",
      "Epoch 23/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0296 - val_loss: 0.0333\n",
      "Epoch 24/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0294 - val_loss: 0.0331\n",
      "Epoch 25/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0293 - val_loss: 0.0330\n",
      "Epoch 26/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0290 - val_loss: 0.0330\n",
      "Epoch 27/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0291 - val_loss: 0.0329\n",
      "Epoch 28/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0287 - val_loss: 0.0329\n",
      "Epoch 29/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0287 - val_loss: 0.0329\n",
      "Epoch 30/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0288 - val_loss: 0.0329\n",
      "Epoch 31/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0287 - val_loss: 0.0328\n",
      "Epoch 32/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0286 - val_loss: 0.0328\n",
      "Epoch 33/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0285 - val_loss: 0.0328\n",
      "Epoch 34/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0287 - val_loss: 0.0328\n",
      "Epoch 35/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0287 - val_loss: 0.0328\n",
      "Epoch 36/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0286 - val_loss: 0.0328\n",
      "Epoch 37/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0283 - val_loss: 0.0328\n",
      "Epoch 38/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0284 - val_loss: 0.0328\n",
      "Epoch 39/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0284 - val_loss: 0.0328\n",
      "Epoch 40/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0284 - val_loss: 0.0328\n",
      "Epoch 41/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0285 - val_loss: 0.0328\n",
      "Epoch 42/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0283 - val_loss: 0.0328\n",
      "Epoch 43/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0287 - val_loss: 0.0328\n",
      "Epoch 44/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0283 - val_loss: 0.0328\n",
      "Epoch 45/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0283 - val_loss: 0.0328\n",
      "Epoch 46/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0286 - val_loss: 0.0328\n",
      "Epoch 47/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0283 - val_loss: 0.0328\n",
      "Epoch 48/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0284 - val_loss: 0.0328\n",
      "Epoch 49/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0283 - val_loss: 0.0328\n",
      "Epoch 50/50\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0286 - val_loss: 0.0328\n",
      "WARNING:tensorflow:5 out of the last 17 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000021BDF1D21F0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n"
     ]
    }
   ],
   "source": [
    "# Get the best hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(f\"Best Encoding Dim: {best_hps.get('encoding_dim')}\")\n",
    "print(f\"Best Layer 1 Units: {best_hps.get('units1')}, Activation: {best_hps.get('activation1')}\")\n",
    "print(f\"Best Layer 2 Units: {best_hps.get('units2')}, Activation: {best_hps.get('activation2')}\")\n",
    "print(f\"Best Learning Rate: {best_hps.get('learning_rate')}\")\n",
    "\n",
    "# Train Autoencoder with best hyperparameters\n",
    "best_autoencoder = tuner.hypermodel.build(best_hps)\n",
    "history = best_autoencoder.fit(X_train, X_train, epochs=50, batch_size=16, shuffle=True, validation_data=(X_test, X_test))\n",
    "\n",
    "# Extract Encoder Model\n",
    "encoder = Model(best_autoencoder.input, best_autoencoder.layers[1].output)  # Extract latent space representation\n",
    "\n",
    "# Generate latent space representation (Employee Scores)\n",
    "employee_scores = encoder.predict(df_pca)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(employee_scores.shape[1]):\n",
    "    df[f'LatentFeature_{i+1}'] = employee_scores[:, i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['SuitabilityScore_AE(Hybrid)'] = np.abs(df[[f'LatentFeature_{i+1}' for i in range(employee_scores.shape[1])]]).mean(axis=1)\n",
    "latent_features=df[[f'LatentFeature_{i+1}' for i in range(best_hps.get('encoding_dim'))]]\n",
    "df['SuitabilityScore_AE_normhy'] = np.linalg.norm(latent_features, axis=1)\n",
    "df['SuitabilityScore_AE_norm_scalehy'] =mn.fit_transform(df[['SuitabilityScore_AE_normhy']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Technical Score_JD</th>\n",
       "      <th>Programming Score_JD</th>\n",
       "      <th>Soft Score_with_JD</th>\n",
       "      <th>Education_match_Score_with_JD</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Department</th>\n",
       "      <th>JobCategory</th>\n",
       "      <th>ProficiencyLevel</th>\n",
       "      <th>Education Qualifications</th>\n",
       "      <th>...</th>\n",
       "      <th>LatentFeature_1</th>\n",
       "      <th>LatentFeature_2</th>\n",
       "      <th>LatentFeature_3</th>\n",
       "      <th>LatentFeature_4</th>\n",
       "      <th>LatentFeature_5</th>\n",
       "      <th>LatentFeature_6</th>\n",
       "      <th>LatentFeature_7</th>\n",
       "      <th>LatentFeature_8</th>\n",
       "      <th>SuitabilityScore_AE_normhy</th>\n",
       "      <th>SuitabilityScore_AE_norm_scalehy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.257062</td>\n",
       "      <td>0.667620</td>\n",
       "      <td>0.468664</td>\n",
       "      <td>0.573545</td>\n",
       "      <td>Male</td>\n",
       "      <td>41</td>\n",
       "      <td>Data and AI</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Senior</td>\n",
       "      <td>Bachelor of Statistics, Master of Data Analytics</td>\n",
       "      <td>...</td>\n",
       "      <td>0.120783</td>\n",
       "      <td>0.067937</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.260820</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.151934</td>\n",
       "      <td>0.207425</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.138578</td>\n",
       "      <td>0.138697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.171806</td>\n",
       "      <td>0.543745</td>\n",
       "      <td>0.468005</td>\n",
       "      <td>0.648808</td>\n",
       "      <td>Female</td>\n",
       "      <td>33</td>\n",
       "      <td>Data and AI</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Mid-Level</td>\n",
       "      <td>Bachelor of Science</td>\n",
       "      <td>...</td>\n",
       "      <td>0.107476</td>\n",
       "      <td>0.315730</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.175282</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.330888</td>\n",
       "      <td>0.292708</td>\n",
       "      <td>0.316234</td>\n",
       "      <td>0.333521</td>\n",
       "      <td>0.422193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.237569</td>\n",
       "      <td>0.667620</td>\n",
       "      <td>0.509374</td>\n",
       "      <td>0.675198</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>Data and AI</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Mid-Level</td>\n",
       "      <td>Bachelor of Data Science, Master of Data Science</td>\n",
       "      <td>...</td>\n",
       "      <td>0.169468</td>\n",
       "      <td>0.141226</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.123818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.199089</td>\n",
       "      <td>0.070180</td>\n",
       "      <td>0.294286</td>\n",
       "      <td>0.220599</td>\n",
       "      <td>0.257977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.253079</td>\n",
       "      <td>0.646303</td>\n",
       "      <td>0.453373</td>\n",
       "      <td>0.634185</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>Data and AI</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Senior</td>\n",
       "      <td>Bachelor of Applied Statistics, Master of Data...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146198</td>\n",
       "      <td>0.129597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.158594</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.132925</td>\n",
       "      <td>0.318598</td>\n",
       "      <td>0.197726</td>\n",
       "      <td>0.195369</td>\n",
       "      <td>0.221286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.163569</td>\n",
       "      <td>0.646303</td>\n",
       "      <td>0.418016</td>\n",
       "      <td>0.721195</td>\n",
       "      <td>Male</td>\n",
       "      <td>59</td>\n",
       "      <td>Data and AI</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Expert</td>\n",
       "      <td>Bachelor of Data Science, Master of Data Scien...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.201649</td>\n",
       "      <td>0.317528</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.256068</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.082795</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.626583</td>\n",
       "      <td>0.376147</td>\n",
       "      <td>0.484182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Technical Score_JD  Programming Score_JD  Soft Score_with_JD  \\\n",
       "0            0.257062              0.667620            0.468664   \n",
       "1            0.171806              0.543745            0.468005   \n",
       "2            0.237569              0.667620            0.509374   \n",
       "3            0.253079              0.646303            0.453373   \n",
       "4            0.163569              0.646303            0.418016   \n",
       "\n",
       "   Education_match_Score_with_JD  Gender  Age   Department     JobCategory  \\\n",
       "0                       0.573545    Male   41  Data and AI  Data Scientist   \n",
       "1                       0.648808  Female   33  Data and AI   Data Engineer   \n",
       "2                       0.675198    Male   35  Data and AI  Data Scientist   \n",
       "3                       0.634185    Male   42  Data and AI  Data Scientist   \n",
       "4                       0.721195    Male   59  Data and AI    Data Analyst   \n",
       "\n",
       "  ProficiencyLevel                           Education Qualifications  ...  \\\n",
       "0           Senior   Bachelor of Statistics, Master of Data Analytics  ...   \n",
       "1        Mid-Level                                Bachelor of Science  ...   \n",
       "2        Mid-Level   Bachelor of Data Science, Master of Data Science  ...   \n",
       "3           Senior  Bachelor of Applied Statistics, Master of Data...  ...   \n",
       "4           Expert  Bachelor of Data Science, Master of Data Scien...  ...   \n",
       "\n",
       "   LatentFeature_1 LatentFeature_2 LatentFeature_3 LatentFeature_4  \\\n",
       "0         0.120783        0.067937             0.0        0.260820   \n",
       "1         0.107476        0.315730             0.0        0.175282   \n",
       "2         0.169468        0.141226             0.0        0.123818   \n",
       "3         0.146198        0.129597             0.0        0.158594   \n",
       "4         0.201649        0.317528             0.0        0.256068   \n",
       "\n",
       "   LatentFeature_5  LatentFeature_6  LatentFeature_7  LatentFeature_8  \\\n",
       "0              0.0         0.151934         0.207425         0.000000   \n",
       "1              0.0         0.330888         0.292708         0.316234   \n",
       "2              0.0         0.199089         0.070180         0.294286   \n",
       "3              0.0         0.132925         0.318598         0.197726   \n",
       "4              0.0         0.082795         0.000000         0.626583   \n",
       "\n",
       "   SuitabilityScore_AE_normhy  SuitabilityScore_AE_norm_scalehy  \n",
       "0                    0.138578                          0.138697  \n",
       "1                    0.333521                          0.422193  \n",
       "2                    0.220599                          0.257977  \n",
       "3                    0.195369                          0.221286  \n",
       "4                    0.376147                          0.484182  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_excel(\"C://Users//DanukaDilshanRathnay//Desktop//AI-Driven-Job-Role-Fit-Prediction//code//Dataset//Jd_score.xlsx\")\n",
    "df3=pd.read_excel(\"C://Users//DanukaDilshanRathnay//Desktop//AI-Driven-Job-Role-Fit-Prediction//code//Dataset//PCA_scores.xlsx\")\n",
    "df1=df1[['EmployeeCode','JD match Score']]\n",
    "df1['Job_disimilarity']=1-df1['JD match Score']\n",
    "df3=df3[['EmployeeCode','Suitability_score_scaled_PCA']]\n",
    "df4=pd.read_excel(\"C://Users//DanukaDilshanRathnay//Desktop//AI-Driven-Job-Role-Fit-Prediction//code//abc.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAEh = pd.concat([employee_ids.reset_index(drop=True), df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAEh=dfAEh[['EmployeeCode','SuitabilityScore_AE_norm_scalehy']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['EmployeeCode', 'JD match Score', 'Job_disimilarity',\n",
       "       'Suitability_score_scaled_PCA', 'SuitabilityScore_AE_norm_scale'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6=df4.merge(dfAEh,on='EmployeeCode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_disimilarity</th>\n",
       "      <th>Suitability_score_scaled_PCA</th>\n",
       "      <th>SuitabilityScore_AE_norm_scalehy</th>\n",
       "      <th>SuitabilityScore_AE_norm_scale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Job_disimilarity</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.165346</td>\n",
       "      <td>-0.082490</td>\n",
       "      <td>-0.241716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Suitability_score_scaled_PCA</th>\n",
       "      <td>-0.165346</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.156162</td>\n",
       "      <td>0.793256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SuitabilityScore_AE_norm_scalehy</th>\n",
       "      <td>-0.082490</td>\n",
       "      <td>0.156162</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.229135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SuitabilityScore_AE_norm_scale</th>\n",
       "      <td>-0.241716</td>\n",
       "      <td>0.793256</td>\n",
       "      <td>0.229135</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Job_disimilarity  \\\n",
       "Job_disimilarity                          1.000000   \n",
       "Suitability_score_scaled_PCA             -0.165346   \n",
       "SuitabilityScore_AE_norm_scalehy         -0.082490   \n",
       "SuitabilityScore_AE_norm_scale           -0.241716   \n",
       "\n",
       "                                  Suitability_score_scaled_PCA  \\\n",
       "Job_disimilarity                                     -0.165346   \n",
       "Suitability_score_scaled_PCA                          1.000000   \n",
       "SuitabilityScore_AE_norm_scalehy                      0.156162   \n",
       "SuitabilityScore_AE_norm_scale                        0.793256   \n",
       "\n",
       "                                  SuitabilityScore_AE_norm_scalehy  \\\n",
       "Job_disimilarity                                         -0.082490   \n",
       "Suitability_score_scaled_PCA                              0.156162   \n",
       "SuitabilityScore_AE_norm_scalehy                          1.000000   \n",
       "SuitabilityScore_AE_norm_scale                            0.229135   \n",
       "\n",
       "                                  SuitabilityScore_AE_norm_scale  \n",
       "Job_disimilarity                                       -0.241716  \n",
       "Suitability_score_scaled_PCA                            0.793256  \n",
       "SuitabilityScore_AE_norm_scalehy                        0.229135  \n",
       "SuitabilityScore_AE_norm_scale                          1.000000  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6[['Job_disimilarity','Suitability_score_scaled_PCA', 'SuitabilityScore_AE_norm_scalehy','SuitabilityScore_AE_norm_scale']].corr()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
