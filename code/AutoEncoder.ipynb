{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import keras_tuner as kt\n",
    "import random\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "data= pd.read_excel('C://Users//DanukaDilshanRathnay//Desktop//AI-Driven-Job-Role-Fit-Prediction//code//Dataset//Similarity_with_EMP_data.xlsx')\n",
    "# data=pd.read_excel('C://Users//DanukaDilshanRathnay//Desktop//AI-Driven-Job-Role-Fit-Prediction//Merge_data_new8.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data[data['Department']=='Data and AI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EmployeeCode</th>\n",
       "      <th>Technical Score_JD</th>\n",
       "      <th>Programming Score_JD</th>\n",
       "      <th>Soft Score_with_JD</th>\n",
       "      <th>Education_match_Score_with_JD</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Department</th>\n",
       "      <th>JobCategory</th>\n",
       "      <th>ProficiencyLevel</th>\n",
       "      <th>...</th>\n",
       "      <th>Total Experience in Years</th>\n",
       "      <th>Number of Goal Assigned</th>\n",
       "      <th>Number of Goals Achieved</th>\n",
       "      <th>Final Score</th>\n",
       "      <th>Goals Score</th>\n",
       "      <th>Competency Score</th>\n",
       "      <th>Cultural Value Score</th>\n",
       "      <th>Additional Accomplishment Score</th>\n",
       "      <th>Potential Assessment Score</th>\n",
       "      <th>Trait Assessment Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EMP9004</td>\n",
       "      <td>0.257062</td>\n",
       "      <td>0.667620</td>\n",
       "      <td>0.468664</td>\n",
       "      <td>0.573545</td>\n",
       "      <td>Male</td>\n",
       "      <td>41</td>\n",
       "      <td>Data and AI</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Senior</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>34.180251</td>\n",
       "      <td>76.488103</td>\n",
       "      <td>7.08</td>\n",
       "      <td>51.806653</td>\n",
       "      <td>55.141563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EMP9005</td>\n",
       "      <td>0.171806</td>\n",
       "      <td>0.543745</td>\n",
       "      <td>0.468005</td>\n",
       "      <td>0.648808</td>\n",
       "      <td>Female</td>\n",
       "      <td>33</td>\n",
       "      <td>Data and AI</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Mid-Level</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>30.775600</td>\n",
       "      <td>63.895969</td>\n",
       "      <td>1.63</td>\n",
       "      <td>40.425636</td>\n",
       "      <td>54.988743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EMP9009</td>\n",
       "      <td>0.237569</td>\n",
       "      <td>0.667620</td>\n",
       "      <td>0.509374</td>\n",
       "      <td>0.675198</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>Data and AI</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Mid-Level</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>42.857143</td>\n",
       "      <td>20.708582</td>\n",
       "      <td>57.979997</td>\n",
       "      <td>8.01</td>\n",
       "      <td>30.443135</td>\n",
       "      <td>36.977535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EMP9015</td>\n",
       "      <td>0.253079</td>\n",
       "      <td>0.646303</td>\n",
       "      <td>0.453373</td>\n",
       "      <td>0.634185</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>Data and AI</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Senior</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>18.998407</td>\n",
       "      <td>66.495545</td>\n",
       "      <td>5.71</td>\n",
       "      <td>43.893732</td>\n",
       "      <td>45.595596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EMP9021</td>\n",
       "      <td>0.163569</td>\n",
       "      <td>0.646303</td>\n",
       "      <td>0.418016</td>\n",
       "      <td>0.721195</td>\n",
       "      <td>Male</td>\n",
       "      <td>59</td>\n",
       "      <td>Data and AI</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Expert</td>\n",
       "      <td>...</td>\n",
       "      <td>37</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>56.717347</td>\n",
       "      <td>73.333333</td>\n",
       "      <td>32.126666</td>\n",
       "      <td>78.174790</td>\n",
       "      <td>2.63</td>\n",
       "      <td>61.771810</td>\n",
       "      <td>50.283365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  EmployeeCode  Technical Score_JD  Programming Score_JD  Soft Score_with_JD  \\\n",
       "0      EMP9004            0.257062              0.667620            0.468664   \n",
       "1      EMP9005            0.171806              0.543745            0.468005   \n",
       "2      EMP9009            0.237569              0.667620            0.509374   \n",
       "3      EMP9015            0.253079              0.646303            0.453373   \n",
       "4      EMP9021            0.163569              0.646303            0.418016   \n",
       "\n",
       "   Education_match_Score_with_JD  Gender  Age   Department     JobCategory  \\\n",
       "0                       0.573545    Male   41  Data and AI  Data Scientist   \n",
       "1                       0.648808  Female   33  Data and AI   Data Engineer   \n",
       "2                       0.675198    Male   35  Data and AI  Data Scientist   \n",
       "3                       0.634185    Male   42  Data and AI  Data Scientist   \n",
       "4                       0.721195    Male   59  Data and AI    Data Analyst   \n",
       "\n",
       "  ProficiencyLevel  ... Total Experience in Years  Number of Goal Assigned  \\\n",
       "0           Senior  ...                        19                       10   \n",
       "1        Mid-Level  ...                        11                       10   \n",
       "2        Mid-Level  ...                        13                        7   \n",
       "3           Senior  ...                        20                       10   \n",
       "4           Expert  ...                        37                       15   \n",
       "\n",
       "  Number of Goals Achieved Final Score Goals Score  Competency Score  \\\n",
       "0                        7   35.000000   70.000000         34.180251   \n",
       "1                        5   35.000000   50.000000         30.775600   \n",
       "2                        3   35.000000   42.857143         20.708582   \n",
       "3                        5   35.000000   50.000000         18.998407   \n",
       "4                       11   56.717347   73.333333         32.126666   \n",
       "\n",
       "   Cultural Value Score  Additional Accomplishment Score  \\\n",
       "0             76.488103                             7.08   \n",
       "1             63.895969                             1.63   \n",
       "2             57.979997                             8.01   \n",
       "3             66.495545                             5.71   \n",
       "4             78.174790                             2.63   \n",
       "\n",
       "   Potential Assessment Score  Trait Assessment Score  \n",
       "0                   51.806653               55.141563  \n",
       "1                   40.425636               54.988743  \n",
       "2                   30.443135               36.977535  \n",
       "3                   43.893732               45.595596  \n",
       "4                   61.771810               50.283365  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_ids =data[\"EmployeeCode\"]\n",
    "\n",
    "data= data.drop(columns=[\"EmployeeCode\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "un_col=['Gender','Department', 'JobCategory', 'ProficiencyLevel',\n",
    "       'Education Qualifications', 'Professional Qualifications','Final Score','Age','List of Software Skills','Number of Goal Assigned', 'Number of Goals Achieved','Projects Completed',\"Total Experience in Years\",\"Absentism Rate\"]\n",
    "df=data.drop(columns=un_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Technical Score_JD</th>\n",
       "      <th>Programming Score_JD</th>\n",
       "      <th>Soft Score_with_JD</th>\n",
       "      <th>Education_match_Score_with_JD</th>\n",
       "      <th>Years of Experience in this Company</th>\n",
       "      <th>KPI</th>\n",
       "      <th>Employee Satisfaction Score</th>\n",
       "      <th>Experience in Years Previous Positions</th>\n",
       "      <th>Goals Score</th>\n",
       "      <th>Competency Score</th>\n",
       "      <th>Cultural Value Score</th>\n",
       "      <th>Additional Accomplishment Score</th>\n",
       "      <th>Potential Assessment Score</th>\n",
       "      <th>Trait Assessment Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.257062</td>\n",
       "      <td>0.667620</td>\n",
       "      <td>0.468664</td>\n",
       "      <td>0.573545</td>\n",
       "      <td>5</td>\n",
       "      <td>38.865258</td>\n",
       "      <td>82.68</td>\n",
       "      <td>14</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>34.180251</td>\n",
       "      <td>76.488103</td>\n",
       "      <td>7.08</td>\n",
       "      <td>51.806653</td>\n",
       "      <td>55.141563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.171806</td>\n",
       "      <td>0.543745</td>\n",
       "      <td>0.468005</td>\n",
       "      <td>0.648808</td>\n",
       "      <td>6</td>\n",
       "      <td>37.089484</td>\n",
       "      <td>68.07</td>\n",
       "      <td>5</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>30.775600</td>\n",
       "      <td>63.895969</td>\n",
       "      <td>1.63</td>\n",
       "      <td>40.425636</td>\n",
       "      <td>54.988743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.237569</td>\n",
       "      <td>0.667620</td>\n",
       "      <td>0.509374</td>\n",
       "      <td>0.675198</td>\n",
       "      <td>2</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>82.60</td>\n",
       "      <td>11</td>\n",
       "      <td>42.857143</td>\n",
       "      <td>20.708582</td>\n",
       "      <td>57.979997</td>\n",
       "      <td>8.01</td>\n",
       "      <td>30.443135</td>\n",
       "      <td>36.977535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.253079</td>\n",
       "      <td>0.646303</td>\n",
       "      <td>0.453373</td>\n",
       "      <td>0.634185</td>\n",
       "      <td>2</td>\n",
       "      <td>31.188340</td>\n",
       "      <td>72.13</td>\n",
       "      <td>18</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>18.998407</td>\n",
       "      <td>66.495545</td>\n",
       "      <td>5.71</td>\n",
       "      <td>43.893732</td>\n",
       "      <td>45.595596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.163569</td>\n",
       "      <td>0.646303</td>\n",
       "      <td>0.418016</td>\n",
       "      <td>0.721195</td>\n",
       "      <td>14</td>\n",
       "      <td>52.928402</td>\n",
       "      <td>96.43</td>\n",
       "      <td>23</td>\n",
       "      <td>73.333333</td>\n",
       "      <td>32.126666</td>\n",
       "      <td>78.174790</td>\n",
       "      <td>2.63</td>\n",
       "      <td>61.771810</td>\n",
       "      <td>50.283365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Technical Score_JD  Programming Score_JD  Soft Score_with_JD  \\\n",
       "0            0.257062              0.667620            0.468664   \n",
       "1            0.171806              0.543745            0.468005   \n",
       "2            0.237569              0.667620            0.509374   \n",
       "3            0.253079              0.646303            0.453373   \n",
       "4            0.163569              0.646303            0.418016   \n",
       "\n",
       "   Education_match_Score_with_JD  Years of Experience in this Company  \\\n",
       "0                       0.573545                                    5   \n",
       "1                       0.648808                                    6   \n",
       "2                       0.675198                                    2   \n",
       "3                       0.634185                                    2   \n",
       "4                       0.721195                                   14   \n",
       "\n",
       "         KPI  Employee Satisfaction Score  \\\n",
       "0  38.865258                        82.68   \n",
       "1  37.089484                        68.07   \n",
       "2  30.000000                        82.60   \n",
       "3  31.188340                        72.13   \n",
       "4  52.928402                        96.43   \n",
       "\n",
       "   Experience in Years Previous Positions  Goals Score  Competency Score  \\\n",
       "0                                      14    70.000000         34.180251   \n",
       "1                                       5    50.000000         30.775600   \n",
       "2                                      11    42.857143         20.708582   \n",
       "3                                      18    50.000000         18.998407   \n",
       "4                                      23    73.333333         32.126666   \n",
       "\n",
       "   Cultural Value Score  Additional Accomplishment Score  \\\n",
       "0             76.488103                             7.08   \n",
       "1             63.895969                             1.63   \n",
       "2             57.979997                             8.01   \n",
       "3             66.495545                             5.71   \n",
       "4             78.174790                             2.63   \n",
       "\n",
       "   Potential Assessment Score  Trait Assessment Score  \n",
       "0                   51.806653               55.141563  \n",
       "1                   40.425636               54.988743  \n",
       "2                   30.443135               36.977535  \n",
       "3                   43.893732               45.595596  \n",
       "4                   61.771810               50.283365  "
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize numerical data\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train/test sets\n",
    "X_train, X_test = train_test_split(scaled_data, test_size=0.3, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define Autoencoder Model\n",
    "# input_dim = X_train.shape[1]\n",
    "# encoding_dim = 9  # Latent space\n",
    "\n",
    "# input_layer = Input(shape=(input_dim,))\n",
    "# encoded = Dense(12, activation='relu')(input_layer)\n",
    "# encoded = Dense(encoding_dim, activation='relu')(encoded)\n",
    "# decoded = Dense(12, activation='relu')(encoded)\n",
    "# decoded = Dense(input_dim, activation='sigmoid')(decoded)\n",
    "\n",
    "# autoencoder = Model(input_layer, decoded)\n",
    "# autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# # Train Autoencoder\n",
    "# autoencoder.fit(X_train, X_train, epochs=50, batch_size=16, shuffle=True, validation_data=(X_test, X_test))\n",
    "\n",
    "# # Extract Encoder Model\n",
    "# encoder = Model(input_layer, encoded)\n",
    "\n",
    "# # Generate latent space representation (Employee Scores)\n",
    "# employee_scores = encoder.predict(scaled_data)\n",
    "\n",
    "# # Add latent score to dataset\n",
    "# for i in range(encoding_dim):\n",
    "#     data[f'LatentFeature_{i+1}'] = employee_scores[:, i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from autoencoder_tuning\\employee_autoencoder\\tuner0.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.regularizers import l2, l1\n",
    "import keras_tuner as kt\n",
    "\n",
    "def build_autoencoder(hp):\n",
    "    input_dim = X_train.shape[1]\n",
    "    encoding_dim = hp.Int(\"encoding_dim\", min_value=2, max_value=max(4, input_dim // 2), step=1)  # Reduced max_value\n",
    "\n",
    "    # Regularization strength hyperparameters (more conservative range)\n",
    "    l2_reg = hp.Float(\"l2_reg\", min_value=1e-6, max_value=1e-4, sampling=\"log\")\n",
    "    dropout_rate = hp.Float(\"dropout_rate\", min_value=0.05, max_value=0.2, step=0.05)\n",
    "    l1_reg = hp.Float(\"l1_reg\", min_value=1e-6, max_value=1e-4, sampling=\"log\")  # Sparsity regularization\n",
    "\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "\n",
    "    # First hidden layer with L2 regularization and dropout\n",
    "    # Fewer units in the first layer\n",
    "    encoded = Dense(hp.Int(\"units1\", min_value=4, max_value=32, step=4),\n",
    "                    activation=hp.Choice(\"activation1\", [\"relu\", \"tanh\"]),\n",
    "                    kernel_regularizer=l2(l2_reg))(input_layer)\n",
    "    encoded = Dropout(dropout_rate)(encoded)\n",
    "\n",
    "    # Latent space with L1 sparsity constraint\n",
    "    encoded = Dense(encoding_dim, activation=\"relu\", activity_regularizer=l1(l1_reg))(encoded)\n",
    "\n",
    "    # Decoder with L2 regularization and dropout\n",
    "    # Simpler decoder\n",
    "    decoded = Dense(hp.Int(\"units2\", min_value=4, max_value=32, step=4),\n",
    "                    activation=hp.Choice(\"activation2\", [\"relu\", \"tanh\"]),\n",
    "                    kernel_regularizer=l2(l2_reg))(encoded)\n",
    "    decoded = Dropout(dropout_rate)(decoded)\n",
    "    decoded = Dense(input_dim, activation=\"sigmoid\")(decoded)\n",
    "\n",
    "    autoencoder = Model(input_layer, decoded)\n",
    "    autoencoder.compile(optimizer=Adam(learning_rate=hp.Choice(\"learning_rate\", [0.001, 0.0005, 0.0001])),\n",
    "                        loss=\"mse\")\n",
    "\n",
    "    return autoencoder\n",
    "\n",
    "# Hyperparameter tuning with Keras Tuner\n",
    "tuner = kt.BayesianOptimization(\n",
    "    build_autoencoder,\n",
    "    objective=\"val_loss\",\n",
    "    max_trials=5,  # Fewer trials to prevent excessive fitting to the small dataset\n",
    "    executions_per_trial=1,  # Reduce the number of executions to minimize variance effects\n",
    "    directory=\"autoencoder_tuning\",\n",
    "    project_name=\"employee_autoencoder\",\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "# Search for the best hyperparameters\n",
    "tuner.search(X_train, X_train, epochs=20, batch_size=8, validation_data=(X_test, X_test))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Encoding Dim: 5\n",
      "Best Layer 1 Units: 32, Activation: relu\n",
      "Best Layer 2 Units: 20, Activation: relu\n",
      "Best Learning Rate: 0.0005\n",
      "Epoch 1/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0755 - val_loss: 0.0803\n",
      "Epoch 2/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0751 - val_loss: 0.0797\n",
      "Epoch 3/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0742 - val_loss: 0.0784\n",
      "Epoch 4/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0726 - val_loss: 0.0763\n",
      "Epoch 5/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0701 - val_loss: 0.0740\n",
      "Epoch 6/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0676 - val_loss: 0.0715\n",
      "Epoch 7/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0652 - val_loss: 0.0689\n",
      "Epoch 8/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0623 - val_loss: 0.0669\n",
      "Epoch 9/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0602 - val_loss: 0.0653\n",
      "Epoch 10/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0591 - val_loss: 0.0641\n",
      "Epoch 11/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0583 - val_loss: 0.0631\n",
      "Epoch 12/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0579 - val_loss: 0.0623\n",
      "Epoch 13/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0568 - val_loss: 0.0617\n",
      "Epoch 14/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0554 - val_loss: 0.0612\n",
      "Epoch 15/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0549 - val_loss: 0.0607\n",
      "Epoch 16/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0546 - val_loss: 0.0603\n",
      "Epoch 17/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0552 - val_loss: 0.0600\n",
      "Epoch 18/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0536 - val_loss: 0.0598\n",
      "Epoch 19/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0551 - val_loss: 0.0595\n",
      "Epoch 20/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0546 - val_loss: 0.0593\n",
      "Epoch 21/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0534 - val_loss: 0.0591\n",
      "Epoch 22/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0540 - val_loss: 0.0589\n",
      "Epoch 23/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0526 - val_loss: 0.0587\n",
      "Epoch 24/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0522 - val_loss: 0.0586\n",
      "Epoch 25/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0539 - val_loss: 0.0584\n",
      "Epoch 26/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0534 - val_loss: 0.0583\n",
      "Epoch 27/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0531 - val_loss: 0.0582\n",
      "Epoch 28/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0519 - val_loss: 0.0580\n",
      "Epoch 29/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0530 - val_loss: 0.0579\n",
      "Epoch 30/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0527 - val_loss: 0.0578\n",
      "Epoch 31/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0526 - val_loss: 0.0577\n",
      "Epoch 32/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0518 - val_loss: 0.0575\n",
      "Epoch 33/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0518 - val_loss: 0.0574\n",
      "Epoch 34/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0522 - val_loss: 0.0572\n",
      "Epoch 35/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0504 - val_loss: 0.0570\n",
      "Epoch 36/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0512 - val_loss: 0.0569\n",
      "Epoch 37/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0513 - val_loss: 0.0568\n",
      "Epoch 38/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0517 - val_loss: 0.0566\n",
      "Epoch 39/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0508 - val_loss: 0.0565\n",
      "Epoch 40/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0505 - val_loss: 0.0563\n",
      "Epoch 41/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0506 - val_loss: 0.0561\n",
      "Epoch 42/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0505 - val_loss: 0.0557\n",
      "Epoch 43/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0508 - val_loss: 0.0554\n",
      "Epoch 44/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0499 - val_loss: 0.0552\n",
      "Epoch 45/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0494 - val_loss: 0.0549\n",
      "Epoch 46/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0496 - val_loss: 0.0545\n",
      "Epoch 47/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0492 - val_loss: 0.0542\n",
      "Epoch 48/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0486 - val_loss: 0.0539\n",
      "Epoch 49/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0480 - val_loss: 0.0536\n",
      "Epoch 50/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0477 - val_loss: 0.0532\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n"
     ]
    }
   ],
   "source": [
    "# Get the best hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(f\"Best Encoding Dim: {best_hps.get('encoding_dim')}\")\n",
    "print(f\"Best Layer 1 Units: {best_hps.get('units1')}, Activation: {best_hps.get('activation1')}\")\n",
    "print(f\"Best Layer 2 Units: {best_hps.get('units2')}, Activation: {best_hps.get('activation2')}\")\n",
    "print(f\"Best Learning Rate: {best_hps.get('learning_rate')}\")\n",
    "\n",
    "# Train Autoencoder with best hyperparameters\n",
    "best_autoencoder = tuner.hypermodel.build(best_hps)\n",
    "history = best_autoencoder.fit(X_train, X_train, epochs=50, batch_size=16, shuffle=True, validation_data=(X_test, X_test))\n",
    "\n",
    "# Extract Encoder Model\n",
    "encoder = Model(best_autoencoder.input, best_autoencoder.layers[1].output)  # Extract latent space representation\n",
    "\n",
    "# Generate latent space representation (Employee Scores)\n",
    "employee_scores = encoder.predict(scaled_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add latent features to dataset\n",
    "for i in range(employee_scores.shape[1]):\n",
    "    data[f'LatentFeature_{i+1}'] = employee_scores[:, i]\n",
    "\n",
    "     \n",
    "# # Save preprocessed data with latent features\n",
    "# df.to_excel(\"employee_autoencoder_scores.xlsx\", index=False)\n",
    "\n",
    "# Save models and scaler\n",
    "# best_autoencoder.save(\"best_autoencoder_model.h5\")\n",
    "# encoder.save(\"encoder_model.h5\")\n",
    "# import joblib\n",
    "# joblib.dump(scaler, \"scaler.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install keras_tuner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Technical Score_JD</th>\n",
       "      <th>Programming Score_JD</th>\n",
       "      <th>Soft Score_with_JD</th>\n",
       "      <th>Education_match_Score_with_JD</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Department</th>\n",
       "      <th>JobCategory</th>\n",
       "      <th>ProficiencyLevel</th>\n",
       "      <th>Education Qualifications</th>\n",
       "      <th>...</th>\n",
       "      <th>LatentFeature_23</th>\n",
       "      <th>LatentFeature_24</th>\n",
       "      <th>LatentFeature_25</th>\n",
       "      <th>LatentFeature_26</th>\n",
       "      <th>LatentFeature_27</th>\n",
       "      <th>LatentFeature_28</th>\n",
       "      <th>LatentFeature_29</th>\n",
       "      <th>LatentFeature_30</th>\n",
       "      <th>LatentFeature_31</th>\n",
       "      <th>LatentFeature_32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.257062</td>\n",
       "      <td>0.667620</td>\n",
       "      <td>0.468664</td>\n",
       "      <td>0.573545</td>\n",
       "      <td>Male</td>\n",
       "      <td>41</td>\n",
       "      <td>Data and AI</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Senior</td>\n",
       "      <td>Bachelor of Statistics, Master of Data Analytics</td>\n",
       "      <td>...</td>\n",
       "      <td>0.873184</td>\n",
       "      <td>0.211250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.352615</td>\n",
       "      <td>0.017170</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.295994</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.580521</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.171806</td>\n",
       "      <td>0.543745</td>\n",
       "      <td>0.468005</td>\n",
       "      <td>0.648808</td>\n",
       "      <td>Female</td>\n",
       "      <td>33</td>\n",
       "      <td>Data and AI</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Mid-Level</td>\n",
       "      <td>Bachelor of Science</td>\n",
       "      <td>...</td>\n",
       "      <td>0.769368</td>\n",
       "      <td>0.032069</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.414658</td>\n",
       "      <td>0.283341</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.191183</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.603163</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.237569</td>\n",
       "      <td>0.667620</td>\n",
       "      <td>0.509374</td>\n",
       "      <td>0.675198</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>Data and AI</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Mid-Level</td>\n",
       "      <td>Bachelor of Data Science, Master of Data Science</td>\n",
       "      <td>...</td>\n",
       "      <td>0.704833</td>\n",
       "      <td>0.110679</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.261962</td>\n",
       "      <td>0.075226</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.383505</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.385316</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.253079</td>\n",
       "      <td>0.646303</td>\n",
       "      <td>0.453373</td>\n",
       "      <td>0.634185</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>Data and AI</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Senior</td>\n",
       "      <td>Bachelor of Applied Statistics, Master of Data...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.672352</td>\n",
       "      <td>0.099283</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.377401</td>\n",
       "      <td>0.027351</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.317702</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.452020</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.163569</td>\n",
       "      <td>0.646303</td>\n",
       "      <td>0.418016</td>\n",
       "      <td>0.721195</td>\n",
       "      <td>Male</td>\n",
       "      <td>59</td>\n",
       "      <td>Data and AI</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Expert</td>\n",
       "      <td>Bachelor of Data Science, Master of Data Scien...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.857069</td>\n",
       "      <td>0.358818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.633058</td>\n",
       "      <td>0.254332</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.444281</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.014998</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Technical Score_JD  Programming Score_JD  Soft Score_with_JD  \\\n",
       "0            0.257062              0.667620            0.468664   \n",
       "1            0.171806              0.543745            0.468005   \n",
       "2            0.237569              0.667620            0.509374   \n",
       "3            0.253079              0.646303            0.453373   \n",
       "4            0.163569              0.646303            0.418016   \n",
       "\n",
       "   Education_match_Score_with_JD  Gender  Age   Department     JobCategory  \\\n",
       "0                       0.573545    Male   41  Data and AI  Data Scientist   \n",
       "1                       0.648808  Female   33  Data and AI   Data Engineer   \n",
       "2                       0.675198    Male   35  Data and AI  Data Scientist   \n",
       "3                       0.634185    Male   42  Data and AI  Data Scientist   \n",
       "4                       0.721195    Male   59  Data and AI    Data Analyst   \n",
       "\n",
       "  ProficiencyLevel                           Education Qualifications  ...  \\\n",
       "0           Senior   Bachelor of Statistics, Master of Data Analytics  ...   \n",
       "1        Mid-Level                                Bachelor of Science  ...   \n",
       "2        Mid-Level   Bachelor of Data Science, Master of Data Science  ...   \n",
       "3           Senior  Bachelor of Applied Statistics, Master of Data...  ...   \n",
       "4           Expert  Bachelor of Data Science, Master of Data Scien...  ...   \n",
       "\n",
       "   LatentFeature_23 LatentFeature_24 LatentFeature_25 LatentFeature_26  \\\n",
       "0          0.873184         0.211250              0.0         0.352615   \n",
       "1          0.769368         0.032069              0.0         0.414658   \n",
       "2          0.704833         0.110679              0.0         0.261962   \n",
       "3          0.672352         0.099283              0.0         0.377401   \n",
       "4          0.857069         0.358818              0.0         0.633058   \n",
       "\n",
       "   LatentFeature_27  LatentFeature_28  LatentFeature_29  LatentFeature_30  \\\n",
       "0          0.017170               0.0          0.295994               0.0   \n",
       "1          0.283341               0.0          0.191183               0.0   \n",
       "2          0.075226               0.0          0.383505               0.0   \n",
       "3          0.027351               0.0          0.317702               0.0   \n",
       "4          0.254332               0.0          0.444281               0.0   \n",
       "\n",
       "   LatentFeature_31  LatentFeature_32  \n",
       "0          0.580521               0.0  \n",
       "1          0.603163               0.0  \n",
       "2          0.385316               0.0  \n",
       "3          0.452020               0.0  \n",
       "4          1.014998               0.0  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['SuitabilityScore_AE'] = np.abs(data[[f'LatentFeature_{i+1}' for i in range(employee_scores.shape[1])]]).mean(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_excel(\"C://Users//DanukaDilshanRathnay//Desktop//AI-Driven-Job-Role-Fit-Prediction//code//Dataset//Jd_score.xlsx\")\n",
    "df3=pd.read_excel(\"C://Users//DanukaDilshanRathnay//Desktop//AI-Driven-Job-Role-Fit-Prediction//code//PCA_score.xlsx\")\n",
    "df1=df1[['EmployeeCode','JD match Score']]\n",
    "df1['Job_disimilarity']=1-df1['JD match Score']\n",
    "df3=df3[['EmployeeCode','Suitability_score_scaled_PCA']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAE = pd.concat([employee_ids.reset_index(drop=True), data], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAE=dfAE[['EmployeeCode','SuitabilityScore_AE']]\n",
    "Suitability_Scores=df1.merge(df3,on='EmployeeCode')\n",
    "Suitability_Scores=Suitability_Scores.merge(dfAE,on='EmployeeCode')\n",
    "Suitability_Scores.to_excel(\"abc.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['EmployeeCode', 'JD match Score', 'Job_disimilarity',\n",
       "       'Suitability_score_scaled_PCA', 'SuitabilityScore_AE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Suitability_Scores.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_disimilarity</th>\n",
       "      <th>Suitability_score_scaled_PCA</th>\n",
       "      <th>SuitabilityScore_AE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Job_disimilarity</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.230778</td>\n",
       "      <td>-0.220722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Suitability_score_scaled_PCA</th>\n",
       "      <td>-0.230778</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.915998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SuitabilityScore_AE</th>\n",
       "      <td>-0.220722</td>\n",
       "      <td>0.915998</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Job_disimilarity  Suitability_score_scaled_PCA  \\\n",
       "Job_disimilarity                      1.000000                     -0.230778   \n",
       "Suitability_score_scaled_PCA         -0.230778                      1.000000   \n",
       "SuitabilityScore_AE                  -0.220722                      0.915998   \n",
       "\n",
       "                              SuitabilityScore_AE  \n",
       "Job_disimilarity                        -0.220722  \n",
       "Suitability_score_scaled_PCA             0.915998  \n",
       "SuitabilityScore_AE                      1.000000  "
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Suitability_Scores[['Job_disimilarity','Suitability_score_scaled_PCA', 'SuitabilityScore_AE']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "Suitability_Scores[['Job_disimilarity','Suitability_score_scaled_PCA', 'SuitabilityScore_AE']].to_excel(\"ff.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   Feature  Importance\n",
      "0                       Technical Score_JD    6.273143\n",
      "10                    Cultural Value Score    6.092610\n",
      "7   Experience in Years Previous Positions    5.937163\n",
      "6              Employee Satisfaction Score    5.760235\n",
      "5                                      KPI    5.594009\n",
      "1                     Programming Score_JD    5.483377\n",
      "3            Education_match_Score_with_JD    5.453515\n",
      "2                       Soft Score_with_JD    5.358584\n",
      "9                         Competency Score    5.045802\n",
      "8                              Goals Score    4.866274\n",
      "4      Years of Experience in this Company    4.495773\n",
      "12              Potential Assessment Score    4.430771\n",
      "13                  Trait Assessment Score    4.422988\n",
      "11         Additional Accomplishment Score    4.403581\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# ✅ Ensure feature names exist\n",
    "if isinstance(df, pd.DataFrame):\n",
    "    feature_names = df.columns.tolist()  # Get actual column names\n",
    "else:\n",
    "    raise ValueError(\"df must be a Pandas DataFrame to retrieve actual column names.\")\n",
    "\n",
    "# ✅ Identify the first Dense layer in the encoder\n",
    "dense_layers = [layer for layer in encoder.layers if isinstance(layer, Dense)]\n",
    "if not dense_layers:\n",
    "    raise ValueError(\"No Dense layers found in the encoder. Check your model structure.\")\n",
    "\n",
    "first_dense_layer = dense_layers[0]  # Get the first Dense layer\n",
    "\n",
    "# ✅ Extract encoder weights\n",
    "encoder_weights = first_dense_layer.get_weights()[0]  # First dense layer weights\n",
    "\n",
    "# ✅ Ensure weight dimensions match the number of features\n",
    "if encoder_weights.shape[0] != len(feature_names):\n",
    "    raise ValueError(f\"Mismatch: Encoder weights have {encoder_weights.shape[0]} inputs, \"\n",
    "                     f\"but feature names list has {len(feature_names)} features.\")\n",
    "\n",
    "# ✅ Compute feature importance as the sum of absolute weights\n",
    "feature_importance = np.sum(np.abs(encoder_weights), axis=1)\n",
    "\n",
    "# ✅ Create a DataFrame with feature names and importance values\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    \"Feature\": feature_names,\n",
    "    \"Importance\": feature_importance\n",
    "})\n",
    "\n",
    "# ✅ Sort features by importance (descending)\n",
    "feature_importance_df = feature_importance_df.sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "# ✅ Display the most influential features\n",
    "print(feature_importance_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "                                        Importance\n",
      "Programming Score_JD                      0.003509\n",
      "Technical Score_JD                        0.002728\n",
      "Soft Score_with_JD                        0.002150\n",
      "Potential Assessment Score                0.001738\n",
      "Years of Experience in this Company       0.001286\n",
      "KPI                                       0.001062\n",
      "Education_match_Score_with_JD             0.000897\n",
      "Cultural Value Score                      0.000829\n",
      "Competency Score                          0.000619\n",
      "Employee Satisfaction Score               0.000545\n",
      "Additional Accomplishment Score           0.000494\n",
      "Goals Score                               0.000334\n",
      "Experience in Years Previous Positions    0.000291\n",
      "Trait Assessment Score                    0.000075\n"
     ]
    }
   ],
   "source": [
    "# X_test_pred = best_autoencoder.predict(X_test)\n",
    "\n",
    "# baseline_loss = np.mean(np.square(X_test - X_test_pred), axis=0)\n",
    "\n",
    "# # Feature importance via reconstruction loss increase\n",
    "# feature_importance = {}\n",
    "# input_dim = X_train.shape[1]\n",
    "# for i in range(input_dim):\n",
    "#     X_test_masked = X_test.copy()\n",
    "#     X_test_masked[:, i] = 0  # Mask one feature at a time\n",
    "#     X_test_pred_masked = best_autoencoder.predict(X_test_masked)\n",
    "#     masked_loss = np.mean(np.square(X_test - X_test_pred_masked), axis=0)\n",
    "#     feature_importance[f'Feature_{i+1}'] = np.mean(masked_loss - baseline_loss)\n",
    "\n",
    "# # Convert feature importance to a sorted DataFrame\n",
    "# feature_importance_df = pd.DataFrame.from_dict(feature_importance, orient='index', columns=['Importance'])\n",
    "# feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "# print(feature_importance_df)\n",
    "\n",
    "feature_names = df.columns.tolist()\n",
    "\n",
    "# Compute baseline reconstruction error\n",
    "X_test_pred = best_autoencoder.predict(X_test)\n",
    "baseline_loss = np.mean(np.square(X_test - X_test_pred), axis=0)\n",
    "\n",
    "# Feature importance via reconstruction loss increase\n",
    "feature_importance = {}\n",
    "input_dim = X_train.shape[1]\n",
    "for i in range(input_dim):\n",
    "    X_test_masked = X_test.copy()\n",
    "    X_test_masked[:, i] = 0  # Mask one feature at a time\n",
    "    X_test_pred_masked = best_autoencoder.predict(X_test_masked)\n",
    "    masked_loss = np.mean(np.square(X_test - X_test_pred_masked), axis=0)\n",
    "    feature_importance[feature_names[i]] = np.mean(masked_loss - baseline_loss)\n",
    "\n",
    "# Convert feature importance to a sorted DataFrame\n",
    "feature_importance_df = pd.DataFrame.from_dict(feature_importance, orient='index', columns=['Importance'])\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Display the results\n",
    "print(feature_importance_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
