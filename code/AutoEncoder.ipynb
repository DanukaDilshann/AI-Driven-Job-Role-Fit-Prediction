{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import keras_tuner as kt\n",
    "import random\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "data= pd.read_excel('C://Users//DanukaDilshanRathnay//Desktop//AI-Driven-Job-Role-Fit-Prediction//code//Dataset//Similarity_with_EMP_data.xlsx')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data[data['Department']=='Data and AI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EmployeeCode</th>\n",
       "      <th>Technical Score_JD</th>\n",
       "      <th>Programming Score_JD</th>\n",
       "      <th>Soft Score_with_JD</th>\n",
       "      <th>Education_match_Score_with_JD</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Department</th>\n",
       "      <th>JobCategory</th>\n",
       "      <th>ProficiencyLevel</th>\n",
       "      <th>...</th>\n",
       "      <th>Total Experience in Years</th>\n",
       "      <th>Number of Goal Assigned</th>\n",
       "      <th>Number of Goals Achieved</th>\n",
       "      <th>Final Score</th>\n",
       "      <th>Goals Score</th>\n",
       "      <th>Competency Score</th>\n",
       "      <th>Cultural Value Score</th>\n",
       "      <th>Additional Accomplishment Score</th>\n",
       "      <th>Potential Assessment Score</th>\n",
       "      <th>Trait Assessment Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EMP9004</td>\n",
       "      <td>0.257062</td>\n",
       "      <td>0.667620</td>\n",
       "      <td>0.468664</td>\n",
       "      <td>0.573545</td>\n",
       "      <td>Male</td>\n",
       "      <td>41</td>\n",
       "      <td>Data and AI</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Senior</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>34.180251</td>\n",
       "      <td>76.488103</td>\n",
       "      <td>7.08</td>\n",
       "      <td>51.806653</td>\n",
       "      <td>55.141563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EMP9005</td>\n",
       "      <td>0.171806</td>\n",
       "      <td>0.543745</td>\n",
       "      <td>0.468005</td>\n",
       "      <td>0.648808</td>\n",
       "      <td>Female</td>\n",
       "      <td>33</td>\n",
       "      <td>Data and AI</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Mid-Level</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>30.775600</td>\n",
       "      <td>63.895969</td>\n",
       "      <td>1.63</td>\n",
       "      <td>40.425636</td>\n",
       "      <td>54.988743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EMP9009</td>\n",
       "      <td>0.237569</td>\n",
       "      <td>0.667620</td>\n",
       "      <td>0.509374</td>\n",
       "      <td>0.675198</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>Data and AI</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Mid-Level</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>42.857143</td>\n",
       "      <td>20.708582</td>\n",
       "      <td>57.979997</td>\n",
       "      <td>8.01</td>\n",
       "      <td>30.443135</td>\n",
       "      <td>36.977535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EMP9015</td>\n",
       "      <td>0.253079</td>\n",
       "      <td>0.646303</td>\n",
       "      <td>0.453373</td>\n",
       "      <td>0.634185</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>Data and AI</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Senior</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>18.998407</td>\n",
       "      <td>66.495545</td>\n",
       "      <td>5.71</td>\n",
       "      <td>43.893732</td>\n",
       "      <td>45.595596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EMP9021</td>\n",
       "      <td>0.163569</td>\n",
       "      <td>0.646303</td>\n",
       "      <td>0.418016</td>\n",
       "      <td>0.721195</td>\n",
       "      <td>Male</td>\n",
       "      <td>59</td>\n",
       "      <td>Data and AI</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Expert</td>\n",
       "      <td>...</td>\n",
       "      <td>37</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>56.717347</td>\n",
       "      <td>73.333333</td>\n",
       "      <td>32.126666</td>\n",
       "      <td>78.174790</td>\n",
       "      <td>2.63</td>\n",
       "      <td>61.771810</td>\n",
       "      <td>50.283365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  EmployeeCode  Technical Score_JD  Programming Score_JD  Soft Score_with_JD  \\\n",
       "0      EMP9004            0.257062              0.667620            0.468664   \n",
       "1      EMP9005            0.171806              0.543745            0.468005   \n",
       "2      EMP9009            0.237569              0.667620            0.509374   \n",
       "3      EMP9015            0.253079              0.646303            0.453373   \n",
       "4      EMP9021            0.163569              0.646303            0.418016   \n",
       "\n",
       "   Education_match_Score_with_JD  Gender  Age   Department     JobCategory  \\\n",
       "0                       0.573545    Male   41  Data and AI  Data Scientist   \n",
       "1                       0.648808  Female   33  Data and AI   Data Engineer   \n",
       "2                       0.675198    Male   35  Data and AI  Data Scientist   \n",
       "3                       0.634185    Male   42  Data and AI  Data Scientist   \n",
       "4                       0.721195    Male   59  Data and AI    Data Analyst   \n",
       "\n",
       "  ProficiencyLevel  ... Total Experience in Years  Number of Goal Assigned  \\\n",
       "0           Senior  ...                        19                       10   \n",
       "1        Mid-Level  ...                        11                       10   \n",
       "2        Mid-Level  ...                        13                        7   \n",
       "3           Senior  ...                        20                       10   \n",
       "4           Expert  ...                        37                       15   \n",
       "\n",
       "  Number of Goals Achieved Final Score Goals Score  Competency Score  \\\n",
       "0                        7   35.000000   70.000000         34.180251   \n",
       "1                        5   35.000000   50.000000         30.775600   \n",
       "2                        3   35.000000   42.857143         20.708582   \n",
       "3                        5   35.000000   50.000000         18.998407   \n",
       "4                       11   56.717347   73.333333         32.126666   \n",
       "\n",
       "   Cultural Value Score  Additional Accomplishment Score  \\\n",
       "0             76.488103                             7.08   \n",
       "1             63.895969                             1.63   \n",
       "2             57.979997                             8.01   \n",
       "3             66.495545                             5.71   \n",
       "4             78.174790                             2.63   \n",
       "\n",
       "   Potential Assessment Score  Trait Assessment Score  \n",
       "0                   51.806653               55.141563  \n",
       "1                   40.425636               54.988743  \n",
       "2                   30.443135               36.977535  \n",
       "3                   43.893732               45.595596  \n",
       "4                   61.771810               50.283365  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_ids =data[\"EmployeeCode\"]\n",
    "\n",
    "data= data.drop(columns=[\"EmployeeCode\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "un_col=['Gender','Department', 'JobCategory', 'ProficiencyLevel',\n",
    "       'Education Qualifications', 'Professional Qualifications','Final Score','Age','List of Software Skills','Number of Goal Assigned', 'Number of Goals Achieved','Projects Completed',\"Total Experience in Years\",\"Absentism Rate\"]\n",
    "df=data.drop(columns=un_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Technical Score_JD</th>\n",
       "      <th>Programming Score_JD</th>\n",
       "      <th>Soft Score_with_JD</th>\n",
       "      <th>Education_match_Score_with_JD</th>\n",
       "      <th>Years of Experience in this Company</th>\n",
       "      <th>KPI</th>\n",
       "      <th>Employee Satisfaction Score</th>\n",
       "      <th>Experience in Years Previous Positions</th>\n",
       "      <th>Goals Score</th>\n",
       "      <th>Competency Score</th>\n",
       "      <th>Cultural Value Score</th>\n",
       "      <th>Additional Accomplishment Score</th>\n",
       "      <th>Potential Assessment Score</th>\n",
       "      <th>Trait Assessment Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.257062</td>\n",
       "      <td>0.667620</td>\n",
       "      <td>0.468664</td>\n",
       "      <td>0.573545</td>\n",
       "      <td>5</td>\n",
       "      <td>38.865258</td>\n",
       "      <td>82.68</td>\n",
       "      <td>14</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>34.180251</td>\n",
       "      <td>76.488103</td>\n",
       "      <td>7.08</td>\n",
       "      <td>51.806653</td>\n",
       "      <td>55.141563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.171806</td>\n",
       "      <td>0.543745</td>\n",
       "      <td>0.468005</td>\n",
       "      <td>0.648808</td>\n",
       "      <td>6</td>\n",
       "      <td>37.089484</td>\n",
       "      <td>68.07</td>\n",
       "      <td>5</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>30.775600</td>\n",
       "      <td>63.895969</td>\n",
       "      <td>1.63</td>\n",
       "      <td>40.425636</td>\n",
       "      <td>54.988743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.237569</td>\n",
       "      <td>0.667620</td>\n",
       "      <td>0.509374</td>\n",
       "      <td>0.675198</td>\n",
       "      <td>2</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>82.60</td>\n",
       "      <td>11</td>\n",
       "      <td>42.857143</td>\n",
       "      <td>20.708582</td>\n",
       "      <td>57.979997</td>\n",
       "      <td>8.01</td>\n",
       "      <td>30.443135</td>\n",
       "      <td>36.977535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.253079</td>\n",
       "      <td>0.646303</td>\n",
       "      <td>0.453373</td>\n",
       "      <td>0.634185</td>\n",
       "      <td>2</td>\n",
       "      <td>31.188340</td>\n",
       "      <td>72.13</td>\n",
       "      <td>18</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>18.998407</td>\n",
       "      <td>66.495545</td>\n",
       "      <td>5.71</td>\n",
       "      <td>43.893732</td>\n",
       "      <td>45.595596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.163569</td>\n",
       "      <td>0.646303</td>\n",
       "      <td>0.418016</td>\n",
       "      <td>0.721195</td>\n",
       "      <td>14</td>\n",
       "      <td>52.928402</td>\n",
       "      <td>96.43</td>\n",
       "      <td>23</td>\n",
       "      <td>73.333333</td>\n",
       "      <td>32.126666</td>\n",
       "      <td>78.174790</td>\n",
       "      <td>2.63</td>\n",
       "      <td>61.771810</td>\n",
       "      <td>50.283365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Technical Score_JD  Programming Score_JD  Soft Score_with_JD  \\\n",
       "0            0.257062              0.667620            0.468664   \n",
       "1            0.171806              0.543745            0.468005   \n",
       "2            0.237569              0.667620            0.509374   \n",
       "3            0.253079              0.646303            0.453373   \n",
       "4            0.163569              0.646303            0.418016   \n",
       "\n",
       "   Education_match_Score_with_JD  Years of Experience in this Company  \\\n",
       "0                       0.573545                                    5   \n",
       "1                       0.648808                                    6   \n",
       "2                       0.675198                                    2   \n",
       "3                       0.634185                                    2   \n",
       "4                       0.721195                                   14   \n",
       "\n",
       "         KPI  Employee Satisfaction Score  \\\n",
       "0  38.865258                        82.68   \n",
       "1  37.089484                        68.07   \n",
       "2  30.000000                        82.60   \n",
       "3  31.188340                        72.13   \n",
       "4  52.928402                        96.43   \n",
       "\n",
       "   Experience in Years Previous Positions  Goals Score  Competency Score  \\\n",
       "0                                      14    70.000000         34.180251   \n",
       "1                                       5    50.000000         30.775600   \n",
       "2                                      11    42.857143         20.708582   \n",
       "3                                      18    50.000000         18.998407   \n",
       "4                                      23    73.333333         32.126666   \n",
       "\n",
       "   Cultural Value Score  Additional Accomplishment Score  \\\n",
       "0             76.488103                             7.08   \n",
       "1             63.895969                             1.63   \n",
       "2             57.979997                             8.01   \n",
       "3             66.495545                             5.71   \n",
       "4             78.174790                             2.63   \n",
       "\n",
       "   Potential Assessment Score  Trait Assessment Score  \n",
       "0                   51.806653               55.141563  \n",
       "1                   40.425636               54.988743  \n",
       "2                   30.443135               36.977535  \n",
       "3                   43.893732               45.595596  \n",
       "4                   61.771810               50.283365  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize numerical data\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train/test sets\n",
    "X_train, X_test = train_test_split(scaled_data, test_size=0.3, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define Autoencoder Model\n",
    "# input_dim = X_train.shape[1]\n",
    "# encoding_dim = 9  # Latent space\n",
    "\n",
    "# input_layer = Input(shape=(input_dim,))\n",
    "# encoded = Dense(12, activation='relu')(input_layer)\n",
    "# encoded = Dense(encoding_dim, activation='relu')(encoded)\n",
    "# decoded = Dense(12, activation='relu')(encoded)\n",
    "# decoded = Dense(input_dim, activation='sigmoid')(decoded)\n",
    "\n",
    "# autoencoder = Model(input_layer, decoded)\n",
    "# autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# # Train Autoencoder\n",
    "# autoencoder.fit(X_train, X_train, epochs=50, batch_size=16, shuffle=True, validation_data=(X_test, X_test))\n",
    "\n",
    "# # Extract Encoder Model\n",
    "# encoder = Model(input_layer, encoded)\n",
    "\n",
    "# # Generate latent space representation (Employee Scores)\n",
    "# employee_scores = encoder.predict(scaled_data)\n",
    "\n",
    "# # Add latent score to dataset\n",
    "# for i in range(encoding_dim):\n",
    "#     data[f'LatentFeature_{i+1}'] = employee_scores[:, i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Technical Score_JD</th>\n",
       "      <th>Programming Score_JD</th>\n",
       "      <th>Soft Score_with_JD</th>\n",
       "      <th>Education_match_Score_with_JD</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Department</th>\n",
       "      <th>JobCategory</th>\n",
       "      <th>ProficiencyLevel</th>\n",
       "      <th>Education Qualifications</th>\n",
       "      <th>...</th>\n",
       "      <th>Total Experience in Years</th>\n",
       "      <th>Number of Goal Assigned</th>\n",
       "      <th>Number of Goals Achieved</th>\n",
       "      <th>Final Score</th>\n",
       "      <th>Goals Score</th>\n",
       "      <th>Competency Score</th>\n",
       "      <th>Cultural Value Score</th>\n",
       "      <th>Additional Accomplishment Score</th>\n",
       "      <th>Potential Assessment Score</th>\n",
       "      <th>Trait Assessment Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.257062</td>\n",
       "      <td>0.667620</td>\n",
       "      <td>0.468664</td>\n",
       "      <td>0.573545</td>\n",
       "      <td>Male</td>\n",
       "      <td>41</td>\n",
       "      <td>Data and AI</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Senior</td>\n",
       "      <td>Bachelor of Statistics, Master of Data Analytics</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>34.180251</td>\n",
       "      <td>76.488103</td>\n",
       "      <td>7.08</td>\n",
       "      <td>51.806653</td>\n",
       "      <td>55.141563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.171806</td>\n",
       "      <td>0.543745</td>\n",
       "      <td>0.468005</td>\n",
       "      <td>0.648808</td>\n",
       "      <td>Female</td>\n",
       "      <td>33</td>\n",
       "      <td>Data and AI</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Mid-Level</td>\n",
       "      <td>Bachelor of Science</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>30.775600</td>\n",
       "      <td>63.895969</td>\n",
       "      <td>1.63</td>\n",
       "      <td>40.425636</td>\n",
       "      <td>54.988743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.237569</td>\n",
       "      <td>0.667620</td>\n",
       "      <td>0.509374</td>\n",
       "      <td>0.675198</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>Data and AI</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Mid-Level</td>\n",
       "      <td>Bachelor of Data Science, Master of Data Science</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>42.857143</td>\n",
       "      <td>20.708582</td>\n",
       "      <td>57.979997</td>\n",
       "      <td>8.01</td>\n",
       "      <td>30.443135</td>\n",
       "      <td>36.977535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.253079</td>\n",
       "      <td>0.646303</td>\n",
       "      <td>0.453373</td>\n",
       "      <td>0.634185</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>Data and AI</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Senior</td>\n",
       "      <td>Bachelor of Applied Statistics, Master of Data...</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>18.998407</td>\n",
       "      <td>66.495545</td>\n",
       "      <td>5.71</td>\n",
       "      <td>43.893732</td>\n",
       "      <td>45.595596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.163569</td>\n",
       "      <td>0.646303</td>\n",
       "      <td>0.418016</td>\n",
       "      <td>0.721195</td>\n",
       "      <td>Male</td>\n",
       "      <td>59</td>\n",
       "      <td>Data and AI</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Expert</td>\n",
       "      <td>Bachelor of Data Science, Master of Data Scien...</td>\n",
       "      <td>...</td>\n",
       "      <td>37</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>56.717347</td>\n",
       "      <td>73.333333</td>\n",
       "      <td>32.126666</td>\n",
       "      <td>78.174790</td>\n",
       "      <td>2.63</td>\n",
       "      <td>61.771810</td>\n",
       "      <td>50.283365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>0.261815</td>\n",
       "      <td>0.667620</td>\n",
       "      <td>0.471770</td>\n",
       "      <td>0.583612</td>\n",
       "      <td>Female</td>\n",
       "      <td>49</td>\n",
       "      <td>Data and AI</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Senior</td>\n",
       "      <td>Bachelor of Statistics</td>\n",
       "      <td>...</td>\n",
       "      <td>27</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>4.322284</td>\n",
       "      <td>60.962473</td>\n",
       "      <td>5.16</td>\n",
       "      <td>23.047758</td>\n",
       "      <td>42.724979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>0.163981</td>\n",
       "      <td>0.620067</td>\n",
       "      <td>0.529479</td>\n",
       "      <td>0.563650</td>\n",
       "      <td>Male</td>\n",
       "      <td>51</td>\n",
       "      <td>Data and AI</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Expert</td>\n",
       "      <td>Bachelor of Applied Statistics</td>\n",
       "      <td>...</td>\n",
       "      <td>29</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>19.021795</td>\n",
       "      <td>73.095125</td>\n",
       "      <td>1.10</td>\n",
       "      <td>45.944417</td>\n",
       "      <td>47.786646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>0.255703</td>\n",
       "      <td>0.620067</td>\n",
       "      <td>0.436235</td>\n",
       "      <td>0.656063</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>Data and AI</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Mid-Level</td>\n",
       "      <td>Bachelor of Engineering, Master of Data Science</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>37.447969</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>31.352049</td>\n",
       "      <td>65.251599</td>\n",
       "      <td>2.64</td>\n",
       "      <td>61.619306</td>\n",
       "      <td>50.820440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>0.265625</td>\n",
       "      <td>0.667620</td>\n",
       "      <td>0.394439</td>\n",
       "      <td>0.721734</td>\n",
       "      <td>Male</td>\n",
       "      <td>24</td>\n",
       "      <td>Data and AI</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Junior</td>\n",
       "      <td>Bachelor of Science, Master of Data Science</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>40.780314</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>17.455393</td>\n",
       "      <td>51.591577</td>\n",
       "      <td>6.69</td>\n",
       "      <td>30.427018</td>\n",
       "      <td>24.134461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>0.267032</td>\n",
       "      <td>0.646303</td>\n",
       "      <td>0.396714</td>\n",
       "      <td>0.549251</td>\n",
       "      <td>Male</td>\n",
       "      <td>46</td>\n",
       "      <td>Data and AI</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Senior</td>\n",
       "      <td>Bachelor of Engineering</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>38.305313</td>\n",
       "      <td>71.428571</td>\n",
       "      <td>18.306652</td>\n",
       "      <td>56.304564</td>\n",
       "      <td>5.95</td>\n",
       "      <td>44.546970</td>\n",
       "      <td>47.520314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Technical Score_JD  Programming Score_JD  Soft Score_with_JD  \\\n",
       "0              0.257062              0.667620            0.468664   \n",
       "1              0.171806              0.543745            0.468005   \n",
       "2              0.237569              0.667620            0.509374   \n",
       "3              0.253079              0.646303            0.453373   \n",
       "4              0.163569              0.646303            0.418016   \n",
       "..                  ...                   ...                 ...   \n",
       "235            0.261815              0.667620            0.471770   \n",
       "236            0.163981              0.620067            0.529479   \n",
       "237            0.255703              0.620067            0.436235   \n",
       "238            0.265625              0.667620            0.394439   \n",
       "239            0.267032              0.646303            0.396714   \n",
       "\n",
       "     Education_match_Score_with_JD  Gender  Age   Department     JobCategory  \\\n",
       "0                         0.573545    Male   41  Data and AI  Data Scientist   \n",
       "1                         0.648808  Female   33  Data and AI   Data Engineer   \n",
       "2                         0.675198    Male   35  Data and AI  Data Scientist   \n",
       "3                         0.634185    Male   42  Data and AI  Data Scientist   \n",
       "4                         0.721195    Male   59  Data and AI    Data Analyst   \n",
       "..                             ...     ...  ...          ...             ...   \n",
       "235                       0.583612  Female   49  Data and AI  Data Scientist   \n",
       "236                       0.563650    Male   51  Data and AI   Data Engineer   \n",
       "237                       0.656063  Female   28  Data and AI  Data Scientist   \n",
       "238                       0.721734    Male   24  Data and AI  Data Scientist   \n",
       "239                       0.549251    Male   46  Data and AI  Data Scientist   \n",
       "\n",
       "    ProficiencyLevel                           Education Qualifications  ...  \\\n",
       "0             Senior   Bachelor of Statistics, Master of Data Analytics  ...   \n",
       "1          Mid-Level                                Bachelor of Science  ...   \n",
       "2          Mid-Level   Bachelor of Data Science, Master of Data Science  ...   \n",
       "3             Senior  Bachelor of Applied Statistics, Master of Data...  ...   \n",
       "4             Expert  Bachelor of Data Science, Master of Data Scien...  ...   \n",
       "..               ...                                                ...  ...   \n",
       "235           Senior                             Bachelor of Statistics  ...   \n",
       "236           Expert                     Bachelor of Applied Statistics  ...   \n",
       "237        Mid-Level    Bachelor of Engineering, Master of Data Science  ...   \n",
       "238           Junior        Bachelor of Science, Master of Data Science  ...   \n",
       "239           Senior                            Bachelor of Engineering  ...   \n",
       "\n",
       "     Total Experience in Years Number of Goal Assigned  \\\n",
       "0                           19                      10   \n",
       "1                           11                      10   \n",
       "2                           13                       7   \n",
       "3                           20                      10   \n",
       "4                           37                      15   \n",
       "..                         ...                     ...   \n",
       "235                         27                      15   \n",
       "236                         29                      14   \n",
       "237                          6                       5   \n",
       "238                          2                       2   \n",
       "239                         24                      14   \n",
       "\n",
       "    Number of Goals Achieved Final Score  Goals Score  Competency Score  \\\n",
       "0                          7   35.000000    70.000000         34.180251   \n",
       "1                          5   35.000000    50.000000         30.775600   \n",
       "2                          3   35.000000    42.857143         20.708582   \n",
       "3                          5   35.000000    50.000000         18.998407   \n",
       "4                         11   56.717347    73.333333         32.126666   \n",
       "..                       ...         ...          ...               ...   \n",
       "235                        6   35.000000    40.000000          4.322284   \n",
       "236                        7   35.000000    50.000000         19.021795   \n",
       "237                        4   37.447969    80.000000         31.352049   \n",
       "238                        1   40.780314    50.000000         17.455393   \n",
       "239                       10   38.305313    71.428571         18.306652   \n",
       "\n",
       "     Cultural Value Score  Additional Accomplishment Score  \\\n",
       "0               76.488103                             7.08   \n",
       "1               63.895969                             1.63   \n",
       "2               57.979997                             8.01   \n",
       "3               66.495545                             5.71   \n",
       "4               78.174790                             2.63   \n",
       "..                    ...                              ...   \n",
       "235             60.962473                             5.16   \n",
       "236             73.095125                             1.10   \n",
       "237             65.251599                             2.64   \n",
       "238             51.591577                             6.69   \n",
       "239             56.304564                             5.95   \n",
       "\n",
       "     Potential Assessment Score  Trait Assessment Score  \n",
       "0                     51.806653               55.141563  \n",
       "1                     40.425636               54.988743  \n",
       "2                     30.443135               36.977535  \n",
       "3                     43.893732               45.595596  \n",
       "4                     61.771810               50.283365  \n",
       "..                          ...                     ...  \n",
       "235                   23.047758               42.724979  \n",
       "236                   45.944417               47.786646  \n",
       "237                   61.619306               50.820440  \n",
       "238                   30.427018               24.134461  \n",
       "239                   44.546970               47.520314  \n",
       "\n",
       "[240 rows x 28 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 00m 06s]\n",
      "val_loss: 1.4113798141479492\n",
      "\n",
      "Best val_loss So Far: 1.040984034538269\n",
      "Total elapsed time: 00h 00m 30s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.regularizers import l2, l1\n",
    "import keras_tuner as kt\n",
    "\n",
    "def build_autoencoder(hp):\n",
    "    input_dim = X_train.shape[1]\n",
    "    encoding_dim = hp.Int(\"encoding_dim\", min_value=2, max_value=max(4, input_dim // 2), step=1)  # Reduced max_value\n",
    "\n",
    "    # Regularization strength hyperparameters (more conservative range)\n",
    "    l2_reg = hp.Float(\"l2_reg\", min_value=1e-6, max_value=1e-4, sampling=\"log\")\n",
    "    dropout_rate = hp.Float(\"dropout_rate\", min_value=0.05, max_value=0.2, step=0.05)\n",
    "    l1_reg = hp.Float(\"l1_reg\", min_value=1e-6, max_value=1e-4, sampling=\"log\")  # Sparsity regularization\n",
    "\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "\n",
    "    # First hidden layer with L2 regularization and dropout\n",
    "    # Fewer units in the first layer\n",
    "    encoded = Dense(hp.Int(\"units1\", min_value=4, max_value=32, step=4),\n",
    "                    activation=hp.Choice(\"activation1\", [\"relu\", \"tanh\"]),\n",
    "                    kernel_regularizer=l2(l2_reg))(input_layer)\n",
    "    encoded = Dropout(dropout_rate)(encoded)\n",
    "\n",
    "    # Latent space with L1 sparsity constraint\n",
    "    encoded = Dense(encoding_dim, activation=\"relu\", activity_regularizer=l1(l1_reg))(encoded)\n",
    "\n",
    "    # Decoder with L2 regularization and dropout\n",
    "    # Simpler decoder\n",
    "    decoded = Dense(hp.Int(\"units2\", min_value=4, max_value=32, step=4),\n",
    "                    activation=hp.Choice(\"activation2\", [\"relu\", \"tanh\"]),\n",
    "                    kernel_regularizer=l2(l2_reg))(encoded)\n",
    "    decoded = Dropout(dropout_rate)(decoded)\n",
    "    decoded = Dense(input_dim, activation=\"sigmoid\")(decoded)\n",
    "\n",
    "    autoencoder = Model(input_layer, decoded)\n",
    "    autoencoder.compile(optimizer=Adam(learning_rate=hp.Choice(\"learning_rate\", [0.001, 0.0005, 0.0001])),\n",
    "                        loss=\"mse\")\n",
    "\n",
    "    return autoencoder\n",
    "\n",
    "# Hyperparameter tuning with Keras Tuner\n",
    "tuner = kt.RandomSearch(\n",
    "    build_autoencoder,\n",
    "    objective=\"val_loss\",\n",
    "    max_trials=5,  # Fewer trials to prevent excessive fitting to the small dataset\n",
    "    executions_per_trial=1,  # Reduce the number of executions to minimize variance effects\n",
    "    directory=\"autoencoder_tuning\",\n",
    "    project_name=\"employee_autoencoder\",\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "# Search for the best hyperparameters\n",
    "tuner.search(X_train, X_train, epochs=20, batch_size=8, validation_data=(X_test, X_test))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Encoding Dim: 5\n",
      "Best Layer 1 Units: 32, Activation: relu\n",
      "Best Layer 2 Units: 20, Activation: relu\n",
      "Best Learning Rate: 0.0005\n",
      "Epoch 1/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 1.1964 - val_loss: 1.4584\n",
      "Epoch 2/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1875 - val_loss: 1.4486\n",
      "Epoch 3/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1792 - val_loss: 1.4389\n",
      "Epoch 4/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1714 - val_loss: 1.4285\n",
      "Epoch 5/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1626 - val_loss: 1.4172\n",
      "Epoch 6/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1558 - val_loss: 1.4050\n",
      "Epoch 7/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1412 - val_loss: 1.3915\n",
      "Epoch 8/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1343 - val_loss: 1.3766\n",
      "Epoch 9/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1268 - val_loss: 1.3609\n",
      "Epoch 10/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1164 - val_loss: 1.3443\n",
      "Epoch 11/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0974 - val_loss: 1.3267\n",
      "Epoch 12/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0858 - val_loss: 1.3086\n",
      "Epoch 13/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0792 - val_loss: 1.2902\n",
      "Epoch 14/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0547 - val_loss: 1.2709\n",
      "Epoch 15/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0477 - val_loss: 1.2508\n",
      "Epoch 16/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0241 - val_loss: 1.2305\n",
      "Epoch 17/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0088 - val_loss: 1.2106\n",
      "Epoch 18/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0022 - val_loss: 1.1915\n",
      "Epoch 19/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.9810 - val_loss: 1.1734\n",
      "Epoch 20/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.9718 - val_loss: 1.1566\n",
      "Epoch 21/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.9559 - val_loss: 1.1413\n",
      "Epoch 22/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.9494 - val_loss: 1.1274\n",
      "Epoch 23/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.9384 - val_loss: 1.1152\n",
      "Epoch 24/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.9176 - val_loss: 1.1044\n",
      "Epoch 25/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.9154 - val_loss: 1.0947\n",
      "Epoch 26/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.9063 - val_loss: 1.0860\n",
      "Epoch 27/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.8992 - val_loss: 1.0777\n",
      "Epoch 28/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.8820 - val_loss: 1.0703\n",
      "Epoch 29/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.8812 - val_loss: 1.0632\n",
      "Epoch 30/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.8800 - val_loss: 1.0567\n",
      "Epoch 31/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.8711 - val_loss: 1.0508\n",
      "Epoch 32/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.8588 - val_loss: 1.0454\n",
      "Epoch 33/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.8540 - val_loss: 1.0403\n",
      "Epoch 34/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.8565 - val_loss: 1.0356\n",
      "Epoch 35/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.8469 - val_loss: 1.0313\n",
      "Epoch 36/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.8335 - val_loss: 1.0273\n",
      "Epoch 37/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.8317 - val_loss: 1.0234\n",
      "Epoch 38/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.8351 - val_loss: 1.0198\n",
      "Epoch 39/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.8228 - val_loss: 1.0164\n",
      "Epoch 40/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.8201 - val_loss: 1.0130\n",
      "Epoch 41/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.8153 - val_loss: 1.0097\n",
      "Epoch 42/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.8154 - val_loss: 1.0064\n",
      "Epoch 43/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.8022 - val_loss: 1.0031\n",
      "Epoch 44/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.8069 - val_loss: 1.0004\n",
      "Epoch 45/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.8025 - val_loss: 0.9978\n",
      "Epoch 46/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.7912 - val_loss: 0.9956\n",
      "Epoch 47/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.7981 - val_loss: 0.9936\n",
      "Epoch 48/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.7921 - val_loss: 0.9915\n",
      "Epoch 49/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.7944 - val_loss: 0.9896\n",
      "Epoch 50/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.7920 - val_loss: 0.9875\n",
      "WARNING:tensorflow:5 out of the last 17 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x00000242560128B0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n"
     ]
    }
   ],
   "source": [
    "#Get the best hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(f\"Best Encoding Dim: {best_hps.get('encoding_dim')}\")\n",
    "print(f\"Best Layer 1 Units: {best_hps.get('units1')}, Activation: {best_hps.get('activation1')}\")\n",
    "print(f\"Best Layer 2 Units: {best_hps.get('units2')}, Activation: {best_hps.get('activation2')}\")\n",
    "print(f\"Best Learning Rate: {best_hps.get('learning_rate')}\")\n",
    "\n",
    "# Train Autoencoder with best hyperparameters\n",
    "best_autoencoder = tuner.hypermodel.build(best_hps)\n",
    "history = best_autoencoder.fit(X_train, X_train, epochs=50, batch_size=16, shuffle=True, validation_data=(X_test, X_test))\n",
    "\n",
    "# Extract Encoder Model\n",
    "encoder = Model(best_autoencoder.input, best_autoencoder.layers[1].output)  # Extract latent space representation\n",
    "\n",
    "# Generate latent space representation (Employee Scores)\n",
    "employee_scores = encoder.predict(scaled_data)\n",
    "# Get the best hyperparameters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Add latent features to dataset\n",
    "for i in range(best_hps.get('encoding_dim')):\n",
    "    data[f'LatentFeature_{i+1}'] = employee_scores[:, i]\n",
    "\n",
    "\n",
    "\n",
    "     \n",
    "# # Save preprocessed data with latent features\n",
    "# df.to_excel(\"employee_autoencoder_scores.xlsx\", index=False)\n",
    "\n",
    "# Save models and scaler\n",
    "# best_autoencoder.save(\"best_autoencoder_model.h5\")\n",
    "# encoder.save(\"encoder_model.h5\")\n",
    "# import joblib\n",
    "# joblib.dump(scaler, \"scaler.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install keras_tuner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Technical Score_JD</th>\n",
       "      <th>Programming Score_JD</th>\n",
       "      <th>Soft Score_with_JD</th>\n",
       "      <th>Education_match_Score_with_JD</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Department</th>\n",
       "      <th>JobCategory</th>\n",
       "      <th>ProficiencyLevel</th>\n",
       "      <th>Education Qualifications</th>\n",
       "      <th>...</th>\n",
       "      <th>Competency Score</th>\n",
       "      <th>Cultural Value Score</th>\n",
       "      <th>Additional Accomplishment Score</th>\n",
       "      <th>Potential Assessment Score</th>\n",
       "      <th>Trait Assessment Score</th>\n",
       "      <th>LatentFeature_1</th>\n",
       "      <th>LatentFeature_2</th>\n",
       "      <th>LatentFeature_3</th>\n",
       "      <th>LatentFeature_4</th>\n",
       "      <th>LatentFeature_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.257062</td>\n",
       "      <td>0.667620</td>\n",
       "      <td>0.468664</td>\n",
       "      <td>0.573545</td>\n",
       "      <td>Male</td>\n",
       "      <td>41</td>\n",
       "      <td>Data and AI</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Senior</td>\n",
       "      <td>Bachelor of Statistics, Master of Data Analytics</td>\n",
       "      <td>...</td>\n",
       "      <td>34.180251</td>\n",
       "      <td>76.488103</td>\n",
       "      <td>7.08</td>\n",
       "      <td>51.806653</td>\n",
       "      <td>55.141563</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.882061</td>\n",
       "      <td>1.137044</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.171806</td>\n",
       "      <td>0.543745</td>\n",
       "      <td>0.468005</td>\n",
       "      <td>0.648808</td>\n",
       "      <td>Female</td>\n",
       "      <td>33</td>\n",
       "      <td>Data and AI</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Mid-Level</td>\n",
       "      <td>Bachelor of Science</td>\n",
       "      <td>...</td>\n",
       "      <td>30.775600</td>\n",
       "      <td>63.895969</td>\n",
       "      <td>1.63</td>\n",
       "      <td>40.425636</td>\n",
       "      <td>54.988743</td>\n",
       "      <td>0.600971</td>\n",
       "      <td>0.095071</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030057</td>\n",
       "      <td>0.698588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.237569</td>\n",
       "      <td>0.667620</td>\n",
       "      <td>0.509374</td>\n",
       "      <td>0.675198</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>Data and AI</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Mid-Level</td>\n",
       "      <td>Bachelor of Data Science, Master of Data Science</td>\n",
       "      <td>...</td>\n",
       "      <td>20.708582</td>\n",
       "      <td>57.979997</td>\n",
       "      <td>8.01</td>\n",
       "      <td>30.443135</td>\n",
       "      <td>36.977535</td>\n",
       "      <td>0.200337</td>\n",
       "      <td>0.418037</td>\n",
       "      <td>0.581746</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.003808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.253079</td>\n",
       "      <td>0.646303</td>\n",
       "      <td>0.453373</td>\n",
       "      <td>0.634185</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>Data and AI</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Senior</td>\n",
       "      <td>Bachelor of Applied Statistics, Master of Data...</td>\n",
       "      <td>...</td>\n",
       "      <td>18.998407</td>\n",
       "      <td>66.495545</td>\n",
       "      <td>5.71</td>\n",
       "      <td>43.893732</td>\n",
       "      <td>45.595596</td>\n",
       "      <td>0.256026</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.028735</td>\n",
       "      <td>0.572480</td>\n",
       "      <td>1.315890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.163569</td>\n",
       "      <td>0.646303</td>\n",
       "      <td>0.418016</td>\n",
       "      <td>0.721195</td>\n",
       "      <td>Male</td>\n",
       "      <td>59</td>\n",
       "      <td>Data and AI</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Expert</td>\n",
       "      <td>Bachelor of Data Science, Master of Data Scien...</td>\n",
       "      <td>...</td>\n",
       "      <td>32.126666</td>\n",
       "      <td>78.174790</td>\n",
       "      <td>2.63</td>\n",
       "      <td>61.771810</td>\n",
       "      <td>50.283365</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.743293</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Technical Score_JD  Programming Score_JD  Soft Score_with_JD  \\\n",
       "0            0.257062              0.667620            0.468664   \n",
       "1            0.171806              0.543745            0.468005   \n",
       "2            0.237569              0.667620            0.509374   \n",
       "3            0.253079              0.646303            0.453373   \n",
       "4            0.163569              0.646303            0.418016   \n",
       "\n",
       "   Education_match_Score_with_JD  Gender  Age   Department     JobCategory  \\\n",
       "0                       0.573545    Male   41  Data and AI  Data Scientist   \n",
       "1                       0.648808  Female   33  Data and AI   Data Engineer   \n",
       "2                       0.675198    Male   35  Data and AI  Data Scientist   \n",
       "3                       0.634185    Male   42  Data and AI  Data Scientist   \n",
       "4                       0.721195    Male   59  Data and AI    Data Analyst   \n",
       "\n",
       "  ProficiencyLevel                           Education Qualifications  ...  \\\n",
       "0           Senior   Bachelor of Statistics, Master of Data Analytics  ...   \n",
       "1        Mid-Level                                Bachelor of Science  ...   \n",
       "2        Mid-Level   Bachelor of Data Science, Master of Data Science  ...   \n",
       "3           Senior  Bachelor of Applied Statistics, Master of Data...  ...   \n",
       "4           Expert  Bachelor of Data Science, Master of Data Scien...  ...   \n",
       "\n",
       "   Competency Score Cultural Value Score Additional Accomplishment Score  \\\n",
       "0         34.180251            76.488103                            7.08   \n",
       "1         30.775600            63.895969                            1.63   \n",
       "2         20.708582            57.979997                            8.01   \n",
       "3         18.998407            66.495545                            5.71   \n",
       "4         32.126666            78.174790                            2.63   \n",
       "\n",
       "  Potential Assessment Score  Trait Assessment Score  LatentFeature_1  \\\n",
       "0                  51.806653               55.141563         0.000000   \n",
       "1                  40.425636               54.988743         0.600971   \n",
       "2                  30.443135               36.977535         0.200337   \n",
       "3                  43.893732               45.595596         0.256026   \n",
       "4                  61.771810               50.283365         0.000000   \n",
       "\n",
       "   LatentFeature_2  LatentFeature_3  LatentFeature_4  LatentFeature_5  \n",
       "0         0.000000         0.882061         1.137044         0.000000  \n",
       "1         0.095071         0.000000         0.030057         0.698588  \n",
       "2         0.418037         0.581746         0.000000         1.003808  \n",
       "3         0.000000         1.028735         0.572480         1.315890  \n",
       "4         0.000000         0.000000         1.743293         0.000000  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LatentFeature_1</th>\n",
       "      <th>LatentFeature_2</th>\n",
       "      <th>LatentFeature_3</th>\n",
       "      <th>LatentFeature_4</th>\n",
       "      <th>LatentFeature_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.882061</td>\n",
       "      <td>1.137044</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.600971</td>\n",
       "      <td>0.095071</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030057</td>\n",
       "      <td>0.698588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.200337</td>\n",
       "      <td>0.418037</td>\n",
       "      <td>0.581746</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.003808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.256026</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.028735</td>\n",
       "      <td>0.572480</td>\n",
       "      <td>1.315890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.743293</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LatentFeature_1  LatentFeature_2  LatentFeature_3  LatentFeature_4  \\\n",
       "0         0.000000         0.000000         0.882061         1.137044   \n",
       "1         0.600971         0.095071         0.000000         0.030057   \n",
       "2         0.200337         0.418037         0.581746         0.000000   \n",
       "3         0.256026         0.000000         1.028735         0.572480   \n",
       "4         0.000000         0.000000         0.000000         1.743293   \n",
       "\n",
       "   LatentFeature_5  \n",
       "0         0.000000  \n",
       "1         0.698588  \n",
       "2         1.003808  \n",
       "3         1.315890  \n",
       "4         0.000000  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[[f'LatentFeature_{i+1}' for i in range(best_hps.get('encoding_dim'))]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['SuitabilityScore_AE'] = np.abs(data[[f'LatentFeature_{i+1}' for i in range(best_hps.get('encoding_dim'))]]).mean(axis=1)\n",
    "data['SuitabilityScore_AE_scaled']=scaler.fit_transform(data[['SuitabilityScore_AE']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_excel(\"C://Users//DanukaDilshanRathnay//Desktop//AI-Driven-Job-Role-Fit-Prediction//code//Dataset//Jd_score.xlsx\")\n",
    "df3=pd.read_excel(\"C://Users//DanukaDilshanRathnay//Desktop//AI-Driven-Job-Role-Fit-Prediction//code//Dataset//PCA_scores.xlsx\")\n",
    "df1=df1[['EmployeeCode','JD match Score']]\n",
    "df1['Job_disimilarity']=1-df1['JD match Score']\n",
    "df3=df3[['EmployeeCode','Suitability_score_scaled_PCA']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAE = pd.concat([employee_ids.reset_index(drop=True), data], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAE=dfAE[['EmployeeCode','SuitabilityScore_AE_scaled']]\n",
    "Suitability_Scores=df1.merge(df3,on='EmployeeCode')\n",
    "Suitability_Scores=Suitability_Scores.merge(dfAE,on='EmployeeCode')\n",
    "Suitability_Scores.to_excel(\"abc.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EmployeeCode</th>\n",
       "      <th>SuitabilityScore_AE_scaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>EMP9683</td>\n",
       "      <td>3.941556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>EMP9381</td>\n",
       "      <td>3.865644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>EMP9357</td>\n",
       "      <td>3.053758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>EMP9700</td>\n",
       "      <td>2.948349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>EMP9479</td>\n",
       "      <td>2.466165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>EMP9843</td>\n",
       "      <td>2.387930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>EMP9771</td>\n",
       "      <td>2.309352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>EMP9333</td>\n",
       "      <td>2.207545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>EMP9883</td>\n",
       "      <td>2.163683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>EMP9541</td>\n",
       "      <td>2.057557</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    EmployeeCode  SuitabilityScore_AE_scaled\n",
       "161      EMP9683                    3.941556\n",
       "79       EMP9381                    3.865644\n",
       "72       EMP9357                    3.053758\n",
       "165      EMP9700                    2.948349\n",
       "99       EMP9479                    2.466165\n",
       "194      EMP9843                    2.387930\n",
       "181      EMP9771                    2.309352\n",
       "66       EMP9333                    2.207545\n",
       "209      EMP9883                    2.163683\n",
       "120      EMP9541                    2.057557"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfAE.sort_values('SuitabilityScore_AE_scaled',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAE.to_excel('C://Users//DanukaDilshanRathnay//Desktop//AI-Driven-Job-Role-Fit-Prediction//code//Dataset//Autoencoder_score.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['EmployeeCode', 'JD match Score', 'Job_disimilarity',\n",
       "       'Suitability_score_scaled_PCA', 'SuitabilityScore_AE_scaled'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Suitability_Scores.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_disimilarity</th>\n",
       "      <th>Suitability_score_scaled_PCA</th>\n",
       "      <th>SuitabilityScore_AE_scaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Job_disimilarity</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.239900</td>\n",
       "      <td>0.078047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Suitability_score_scaled_PCA</th>\n",
       "      <td>-0.239900</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.745846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SuitabilityScore_AE_scaled</th>\n",
       "      <td>0.078047</td>\n",
       "      <td>-0.745846</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Job_disimilarity  Suitability_score_scaled_PCA  \\\n",
       "Job_disimilarity                      1.000000                     -0.239900   \n",
       "Suitability_score_scaled_PCA         -0.239900                      1.000000   \n",
       "SuitabilityScore_AE_scaled            0.078047                     -0.745846   \n",
       "\n",
       "                              SuitabilityScore_AE_scaled  \n",
       "Job_disimilarity                                0.078047  \n",
       "Suitability_score_scaled_PCA                   -0.745846  \n",
       "SuitabilityScore_AE_scaled                      1.000000  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Suitability_Scores[['Job_disimilarity','Suitability_score_scaled_PCA', 'SuitabilityScore_AE_scaled']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suitability_Scores[['Job_disimilarity','Suitability_score_scaled_PCA', 'SuitabilityScore_AE']].to_excel(\"ff.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   Feature  Importance\n",
      "12              Potential Assessment Score    7.721225\n",
      "0                       Technical Score_JD    7.681297\n",
      "4      Years of Experience in this Company    7.063509\n",
      "8                              Goals Score    7.020782\n",
      "9                         Competency Score    6.991130\n",
      "1                     Programming Score_JD    6.729298\n",
      "13                  Trait Assessment Score    6.710367\n",
      "10                    Cultural Value Score    6.666288\n",
      "11         Additional Accomplishment Score    6.623199\n",
      "7   Experience in Years Previous Positions    6.582819\n",
      "5                                      KPI    6.560937\n",
      "2                       Soft Score_with_JD    6.367979\n",
      "3            Education_match_Score_with_JD    6.203355\n",
      "6              Employee Satisfaction Score    5.346385\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#  Ensure feature names exist\n",
    "if isinstance(df, pd.DataFrame):\n",
    "    feature_names = df.columns.tolist()  # Get actual column names\n",
    "else:\n",
    "    raise ValueError(\"df must be a Pandas DataFrame to retrieve actual column names.\")\n",
    "\n",
    "#  Identify the first Dense layer in the encoder\n",
    "dense_layers = [layer for layer in encoder.layers if isinstance(layer, Dense)]\n",
    "if not dense_layers:\n",
    "    raise ValueError(\"No Dense layers found in the encoder. Check your model structure.\")\n",
    "\n",
    "first_dense_layer = dense_layers[0]  # Get the first Dense layer\n",
    "\n",
    "#  Extract encoder weights\n",
    "encoder_weights = first_dense_layer.get_weights()[0]  # First dense layer weights\n",
    "\n",
    "#  Ensure weight dimensions match the number of features\n",
    "if encoder_weights.shape[0] != len(feature_names):\n",
    "    raise ValueError(f\"Mismatch: Encoder weights have {encoder_weights.shape[0]} inputs, \"\n",
    "                     f\"but feature names list has {len(feature_names)} features.\")\n",
    "\n",
    "# Compute feature importance as the sum of absolute weights\n",
    "feature_importance = np.sum(np.abs(encoder_weights), axis=1)\n",
    "\n",
    "#  Create a DataFrame with feature names and importance values\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    \"Feature\": feature_names,\n",
    "    \"Importance\": feature_importance\n",
    "})\n",
    "\n",
    "# Sort features by importance (descending)\n",
    "feature_importance_df = feature_importance_df.sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "# Display the most influential features\n",
    "print(feature_importance_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 17 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000024257022940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "                                        Importance\n",
      "Years of Experience in this Company       0.010470\n",
      "Cultural Value Score                      0.010417\n",
      "Trait Assessment Score                    0.007437\n",
      "Potential Assessment Score                0.007189\n",
      "Technical Score_JD                        0.006231\n",
      "KPI                                       0.006120\n",
      "Goals Score                               0.006078\n",
      "Competency Score                          0.005607\n",
      "Experience in Years Previous Positions    0.004751\n",
      "Employee Satisfaction Score               0.003457\n",
      "Additional Accomplishment Score           0.003405\n",
      "Education_match_Score_with_JD             0.002780\n",
      "Soft Score_with_JD                        0.002729\n",
      "Programming Score_JD                     -0.001511\n"
     ]
    }
   ],
   "source": [
    "# X_test_pred = best_autoencoder.predict(X_test)\n",
    "\n",
    "# baseline_loss = np.mean(np.square(X_test - X_test_pred), axis=0)\n",
    "\n",
    "# # Feature importance via reconstruction loss increase\n",
    "# feature_importance = {}\n",
    "# input_dim = X_train.shape[1]\n",
    "# for i in range(input_dim):\n",
    "#     X_test_masked = X_test.copy()\n",
    "#     X_test_masked[:, i] = 0  # Mask one feature at a time\n",
    "#     X_test_pred_masked = best_autoencoder.predict(X_test_masked)\n",
    "#     masked_loss = np.mean(np.square(X_test - X_test_pred_masked), axis=0)\n",
    "#     feature_importance[f'Feature_{i+1}'] = np.mean(masked_loss - baseline_loss)\n",
    "\n",
    "# # Convert feature importance to a sorted DataFrame\n",
    "# feature_importance_df = pd.DataFrame.from_dict(feature_importance, orient='index', columns=['Importance'])\n",
    "# feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "# print(feature_importance_df)\n",
    "\n",
    "feature_names = df.columns.tolist()\n",
    "\n",
    "# Compute baseline reconstruction error\n",
    "X_test_pred = best_autoencoder.predict(X_test)\n",
    "baseline_loss = np.mean(np.square(X_test - X_test_pred), axis=0)\n",
    "\n",
    "# Feature importance via reconstruction loss increase\n",
    "feature_importance = {}\n",
    "input_dim = X_train.shape[1]\n",
    "for i in range(input_dim):\n",
    "    X_test_masked = X_test.copy()\n",
    "    X_test_masked[:, i] = 0  # Mask one feature at a time\n",
    "    X_test_pred_masked = best_autoencoder.predict(X_test_masked)\n",
    "    masked_loss = np.mean(np.square(X_test - X_test_pred_masked), axis=0)\n",
    "    feature_importance[feature_names[i]] = np.mean(masked_loss - baseline_loss)\n",
    "\n",
    "# Convert feature importance to a sorted DataFrame\n",
    "feature_importance_df = pd.DataFrame.from_dict(feature_importance, orient='index', columns=['Importance'])\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Display the results\n",
    "print(feature_importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Average Reconstruction Error: 0.9868148277483458\n",
      "Reconstruction Errors: 0.9868148277483458\n"
     ]
    }
   ],
   "source": [
    "X_test_pred = best_autoencoder.predict(X_test)\n",
    "\n",
    "# Compute Reconstruction Error\n",
    "reconstruction_error = np.mean(np.power(X_test - X_test_pred, 2), axis=1)\n",
    "reconstruction_errors = np.mean((X_test - X_test_pred) ** 2, axis=1)\n",
    "\n",
    "# Print average error\n",
    "print(f\"Average Reconstruction Error: {np.mean(reconstruction_errors)}\")\n",
    "\n",
    "# Display error values\n",
    "print(\"Reconstruction Errors:\", np.mean(reconstruction_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstruction Errors (MAE): 0.7789750750432365\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Compute Reconstruction Error with MAE\n",
    "reconstruction_error_mae = np.mean(np.abs(X_test - X_test_pred), axis=1)\n",
    "\n",
    "print(\"Reconstruction Errors (MAE):\", np.mean(reconstruction_error_mae))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[72], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minspection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m permutation_importance\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Compute permutation feature importance\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m results \u001b[38;5;241m=\u001b[39m permutation_importance(\u001b[43mmodel\u001b[49m, X_test, y_test, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneg_mean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Create a DataFrame with feature importance scores\u001b[39;00m\n\u001b[0;32m      7\u001b[0m feature_importance_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFeature\u001b[39m\u001b[38;5;124m'\u001b[39m: X_test\u001b[38;5;241m.\u001b[39mcolumns,\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImportance\u001b[39m\u001b[38;5;124m'\u001b[39m: results\u001b[38;5;241m.\u001b[39mimportances_mean\n\u001b[0;32m     10\u001b[0m })\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImportance\u001b[39m\u001b[38;5;124m'\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Compute permutation feature importance\n",
    "results = permutation_importance(model, X_test, y_test, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Create a DataFrame with feature importance scores\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': X_test.columns,\n",
    "    'Importance': results.importances_mean\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(feature_importance_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
